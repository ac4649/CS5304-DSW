{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an index file for the huge data file\n",
    "def createIndex(filePath):\n",
    "    file = open(filePath,'r');\n",
    "    indexFilePath = filePath+\"_index.csv\"\n",
    "    indexFile = open(indexFilePath,'w');\n",
    "    indexFile.close()\n",
    "    \n",
    "    offset = 0\n",
    "    lineNumber = 0\n",
    "    for line in file:\n",
    "#         clear_output(wait=True)\n",
    "#         print(lineNumber)\n",
    "        indexFile = open(indexFilePath,'a');\n",
    "        indexFile.write(str(lineNumber) + \",\" + str(offset) + \"\\n\")\n",
    "        indexFile.close()\n",
    "        lineNumber = lineNumber + 1\n",
    "        offset += len(line)\n",
    "    file.close()\n",
    "    return indexFilePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateNIndecesFrom(n, rangeOfIndeces):\n",
    "    print(\"Generating \" + str(n) + \" indeces from range\")\n",
    "    allIndeces = random.sample(rangeOfIndeces, n)\n",
    "    allIndeces = pd.Series(data = allIndeces)\n",
    "    allIndeces = allIndeces.sort_values().reset_index().drop(['index'],axis=1)\n",
    "    allIndeces.columns = ['Index'];\n",
    "    return allIndeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateAndSaveSubset(file,dataFrame,indexValues,numRowsPerItteration,totalNumRows,column_headers,frameSaveName):\n",
    "    dataFrame = generateSubSet(file,dataFrame,indexValues,numRowsPerItteration,totalNumRows,column_headers)\n",
    "    dataFrame.to_csv(frameSaveName)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateSubSet(file,dataFrame,indexValues,numRowsPerItteration,totalNumRows,column_headers):\n",
    "    totalNumIterations = int(totalNumRows/numRowsPerItteration)\n",
    "    print(\"Number of itterations = \" + str(totalNumIterations))\n",
    "    totalNumRowsTraversed = 0\n",
    "    prevsize = 0\n",
    "    for i in range(totalNumIterations + 1):\n",
    "#         \n",
    "#         print(\"Itteration number: \" + str(i))\n",
    "#         print(\"skipRows: \" + str(i * numRowsPerItteration))\n",
    "#         print(\"Read in : \" + str(numRowsPerItteration))\n",
    "        curData = pd.read_table(file,skiprows = i * numRowsPerItteration, nrows = numRowsPerItteration,header=None)\n",
    "        curData.index = [i for i in range(i*numRowsPerItteration,i*numRowsPerItteration + curData.shape[0])]\n",
    "        totalNumRowsTraversed = totalNumRowsTraversed + curData.shape[0]\n",
    "\n",
    "#         print(curData.shape)\n",
    "#         print(curData.index.shape)\n",
    "\n",
    "        \n",
    "        curData.columns = column_headers\n",
    "        curData['Index'] = curData.index\n",
    "#         print(indexValues)\n",
    "#         break\n",
    "        curIndexRange = indexValues['Index'][(indexValues['Index'] < (i*numRowsPerItteration + numRowsPerItteration)) & (indexValues['Index'] > (i*numRowsPerItteration-1))]\n",
    "        curData = curData[curData['Index'].isin(curIndexRange)]\n",
    "\n",
    "        dataFrame = pd.concat([dataFrame,curData])\n",
    "        \n",
    "        clear_output()\n",
    "        print(\"Extraction Stats: \" + str(dataFrame.shape[0]) + \" percent: \" + str(dataFrame.shape[0] / indexValues.shape[0] * 100) + \"%\")\n",
    "        print(\"Document Stats: \" + str(totalNumRowsTraversed) + \" percent: \" + str(totalNumRowsTraversed/totalNumRows*100) + \"%\")\n",
    "        if (dataFrame.shape[0] - prevsize) > 500000:\n",
    "            prevsize = dataFrame.shape[0]\n",
    "#             dataFrame.to_csv(frameSaveName)\n",
    "        elif dataFrame.shape[0] == indexValues.shape[0]:\n",
    "            print(\"Finished with the data collection\")\n",
    "#             dataFrame.to_csv(frameSaveName)\n",
    "            break\n",
    "    print(\"Extraction is Done, now saving frame\")        \n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were not 2000000 data points\n",
      "Generating 2000000 indeces from range\n"
     ]
    }
   ],
   "source": [
    "#Load or Generate the 2M indeces to use\n",
    "try:\n",
    "    twoMIndeces = pd.read_csv('2MIndeces.csv',squeeze = True)\n",
    "    \n",
    "except:\n",
    "    print(\"There were not 2000000 data points\")\n",
    "    twoMIndeces = generateNIndecesFrom(2000000,range(0,45840617)) # this range is because there are this number of records in the training set.\n",
    "    twoMIndeces.to_csv('2MIndeces.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were not 1000000 data points\n",
      "Generating 1000000 indeces from range\n",
      "Generating 250000 indeces from range\n",
      "Generating 750000 indeces from range\n"
     ]
    }
   ],
   "source": [
    "#Load or Generate the 1M indeces for train, 250k validation and 750k test\n",
    "try:\n",
    "    trainIndeces = pd.read_csv('train_ids.txt',squeeze = True)\n",
    "    validationIndeces = pd.read_csv('validation_ids.txt',squeeze = True)\n",
    "except:\n",
    "    print(\"There were not 1000000 data points\")\n",
    "    trainIndeces = generateNIndecesFrom(1000000,list(twoMIndeces['Index']))\n",
    "    trainIndeces.to_csv('train_ids.txt',index=False,header=False)\n",
    "\n",
    "    remainingIndeces = twoMIndeces['Index'][~twoMIndeces['Index'].isin(trainIndeces.values)]\n",
    "    validationIndeces = generateNIndecesFrom(250000,list(remainingIndeces))\n",
    "    validationIndeces.to_csv('validation_ids.txt',index=False,header=False)\n",
    "    \n",
    "    testingIndeces = twoMIndeces['Index'][~(twoMIndeces['Index'].isin(trainIndeces.values) | twoMIndeces['Index'].isin(validationIndeces.values))]\n",
    "    testingIndeces = generateNIndecesFrom(750000,list(testingIndeces))\n",
    "    testingIndeces.to_csv('testing_ids.txt',index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getColumnHeaders():\n",
    "    return pd.Series(data=['Index','label','integer_1','integer_2','integer_3',\n",
    "                                 'integer_4','integer_5','integer_6','integer_7','integer_8','integer_9'\n",
    "                                 'integer_10','integer_11','integer_12','integer_13','categorical_1',\n",
    "                                 'categorical_2','categorical_3','categorical_4','categorical_5','categorical_6',\n",
    "                                 'categorical_7','categorical_8','categorical_9','categorical_10','categorical_11',\n",
    "                                 'categorical_12','categorical_13','categorical_14','categorical_15','categorical_16',\n",
    "                                 'categorical_17','categorical_18','categorical_19','categorical_20','categorical_21',\n",
    "                                 'categorical_22','categorical_23','categorical_24','categorical_25','categorical_26'])\n",
    "column_headers = getColumnHeaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Stats: 1000000 percent: 100.0%\n",
      "Document Stats: 45840617 percent: 99.6535152173913%\n",
      "Finished with the data collection\n",
      "Extraction is Done, now saving frame\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train1M = pd.read_csv('train1M.csv',squeeze = True)\n",
    "except:\n",
    "    print(\"No 1M collection\")\n",
    "    train1M = pd.DataFrame()\n",
    "    train1M = generateAndSaveSubset('dac/train.txt',train1M,trainIndeces,4000000,46000000,column_headers,'train1M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Stats: 250000 percent: 100.0%\n",
      "Document Stats: 45840617 percent: 99.6535152173913%\n",
      "Finished with the data collection\n",
      "Extraction is Done, now saving frame\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validation250k = pd.read_csv('validation250k.csv',squeeze = True)\n",
    "except:\n",
    "    print(\"No 250k collection\")\n",
    "    validation250k = pd.DataFrame()\n",
    "    validation250k = generateAndSaveSubset('dac/train.txt',validation250k,validationIndeces,4000000,46000000,column_headers,'validation250k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Stats: 250000 percent: 100.0%\n",
      "Document Stats: 45840617 percent: 99.6535152173913%\n",
      "Finished with the data collection\n",
      "Extraction is Done, now saving frame\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test750k = pd.read_csv('test750k.csv',squeeze = True)\n",
    "except:\n",
    "    print(\"No 750k collection\")\n",
    "    test750k = pd.DataFrame()\n",
    "    test750k = generateAndSaveSubset('dac/train.txt',test750k,validationIndeces,4000000,46000000,column_headers,'test750k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 40)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>label</th>\n",
       "      <th>integer_1</th>\n",
       "      <th>integer_2</th>\n",
       "      <th>integer_3</th>\n",
       "      <th>integer_4</th>\n",
       "      <th>integer_5</th>\n",
       "      <th>integer_6</th>\n",
       "      <th>integer_7</th>\n",
       "      <th>integer_8</th>\n",
       "      <th>...</th>\n",
       "      <th>categorical_17</th>\n",
       "      <th>categorical_18</th>\n",
       "      <th>categorical_19</th>\n",
       "      <th>categorical_20</th>\n",
       "      <th>categorical_21</th>\n",
       "      <th>categorical_22</th>\n",
       "      <th>categorical_23</th>\n",
       "      <th>categorical_24</th>\n",
       "      <th>categorical_25</th>\n",
       "      <th>categorical_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3633.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>12195b22</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>fa131867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dbb486d7</td>\n",
       "      <td>8ecc176a</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>c43c3f58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>97029569</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>6ec2bcf7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55dd3565</td>\n",
       "      <td>7f686ab3</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>bebc2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5029.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>2804effd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>723b4dfd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3123.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27c07bd6</td>\n",
       "      <td>e5f8f18f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f3ddd519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17330.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>04d863d5</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a3a82059</td>\n",
       "      <td>78e2e389</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index  label  integer_1  integer_2  integer_3  integer_4  integer_5  \\\n",
       "14      14    0.0         51       84.0        4.0     3633.0       26.0   \n",
       "147    147    0.0          1       14.0        2.0      120.0      733.0   \n",
       "206    206    0.0         76        3.0        NaN     5029.0        NaN   \n",
       "211    211    NaN         -1        NaN        NaN     3123.0       22.0   \n",
       "241    241    NaN         25        1.0        NaN    17330.0       62.0   \n",
       "\n",
       "     integer_6  integer_7  integer_8      ...        categorical_17  \\\n",
       "14         1.0        4.0        8.0      ...              3486227d   \n",
       "147        0.0       12.0      606.0      ...              8efede7f   \n",
       "206        NaN       16.0        NaN      ...              d4bb7bd8   \n",
       "211       48.0        0.0       32.0      ...              27c07bd6   \n",
       "241        1.0        3.0       76.0      ...              07c540c4   \n",
       "\n",
       "     categorical_18  categorical_19  categorical_20 categorical_21  \\\n",
       "14         12195b22        21ddcdc9        b1252a9d       fa131867   \n",
       "147        97029569        21ddcdc9        b1252a9d       6ec2bcf7   \n",
       "206        2804effd             NaN             NaN       723b4dfd   \n",
       "211        e5f8f18f             NaN             NaN       f3ddd519   \n",
       "241        04d863d5        21ddcdc9        b1252a9d       a3a82059   \n",
       "\n",
       "    categorical_22 categorical_23 categorical_24 categorical_25 categorical_26  \n",
       "14             NaN       dbb486d7       8ecc176a       e8b83407       c43c3f58  \n",
       "147            NaN       55dd3565       7f686ab3       2bf691b1       bebc2875  \n",
       "206            NaN       3a171ecb       b34f3128            NaN            NaN  \n",
       "211            NaN       32c7478e       b34f3128            NaN            NaN  \n",
       "241       78e2e389       423fab69       45ab94c8       e8b83407       c84c4aec  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 40)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation250k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 40)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test750k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
