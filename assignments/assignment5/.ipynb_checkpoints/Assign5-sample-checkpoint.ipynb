{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "from scipy.sparse import lil_matrix\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFile = pd.read_csv('LambdaMeanLossResults.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>1.72851</td>\n",
       "      <td>1.72088</td>\n",
       "      <td>1.67337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>1.71202</td>\n",
       "      <td>1.70354</td>\n",
       "      <td>1.65576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>1.71550</td>\n",
       "      <td>1.70717</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.001     0.01      0.1\n",
       "r1  1.72851  1.72088  1.67337\n",
       "r2  1.71202  1.70354  1.65576\n",
       "r3  1.71550  1.70717      NaN\n",
       "r4      NaN      NaN      NaN\n",
       "r5      NaN      NaN      NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Loaded Train\n",
      "Loaded Test\n"
     ]
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "print(\"Loading Data\")\n",
    "df_train = pd.read_csv('ml-10M100K/r3.train', sep='::', names=names,engine='python')\n",
    "print(\"Loaded Train\")\n",
    "df_test = pd.read_csv('ml-10M100K/r3.test', sep='::', names=names,engine='python')\n",
    "print(\"Loaded Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1      122     5.0  838985046\n",
       "1        1      185     5.0  838983525\n",
       "2        1      231     5.0  838983392\n",
       "3        1      292     5.0  838983421\n",
       "4        1      316     5.0  838983392"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000044, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train.head()\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movielens_ratings(df):\n",
    "    n_users = max(df.user_id.unique())\n",
    "    n_items = max(df.item_id.unique())\n",
    "\n",
    "    interactions = lil_matrix( (n_users,n_items), dtype=float) #np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Training Data\n",
      "(71567, 65133)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Training Data\")\n",
    "ratings = get_movielens_ratings(df_train)\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Testing Data\n",
      "(42788, 65133)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Testing Data\")\n",
    "test_ratings = get_movielens_ratings(df_test)\n",
    "print(test_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_users, n_items, n_factors=5, useBias = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if torch.cuda.is_available(): # CHECK FOR CUDA AVAILABILITY\n",
    "            self.useCUDA = True\n",
    "            print(\"CUDA is being used\")\n",
    "        else:\n",
    "            print(\"CUDA not available, reverting to CPU\")\n",
    "            \n",
    "        if self.useCUDA: # IF IT IS AVAILABLE, USE IT\n",
    "            self.cuda() \n",
    "        \n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        # Also should consider fitting overall bias (self.mu term) and both user and item bias vectors\n",
    "        \n",
    "        ## Incorporation of Bias Term\n",
    "        if useBias:\n",
    "            self.user_bias = torch.nn.Embedding(n_users, 1, sparse = False)\n",
    "            self.item_bias = torch.nn.Embedding(n_itms, 1, sparse = False)\n",
    "        \n",
    "        \n",
    "        # Mu is 1x1, user_bias is 1xn_users. item_bias is 1xn_items\n",
    "        \n",
    "    def getLoss(self):\n",
    "        return self.currentLoss.data.cpu().numpy()[0]\n",
    "\n",
    "\n",
    "    currentLoss = 10\n",
    "    useCUDA = False\n",
    "    \n",
    "    interactions = False\n",
    "#     loss_func = torch.nn.MSELoss()\n",
    "#     reg_loss_func = torch.optim.SGD(self.model.parameters(), lr=1e-6, weight_decay=1e-3)\n",
    "    \n",
    "    # For convenience when we want to predict a single user-item pair. \n",
    "    def predict(self, user, item):\n",
    "        # Need to fit bias factorsx\n",
    "        print(\"Predicting\")\n",
    "        \n",
    "        print(self.user_factors(user))\n",
    "        print(torch.transpose(self.item_factors(item),0,1))\n",
    "\n",
    "#         return torch.mm(self.user_factors(user)[0],torch.transpose(self.item_factors(item),0,1)[0])\n",
    "        return torch.mm(self.user_factors(user),torch.transpose(self.item_factors(item),0,1))\n",
    "    \n",
    "    \n",
    "#         return torch.dot(self.user_factors(user),self.item_factors(item))\n",
    "    \n",
    "    # Much more efficient batch operator. This should be used for training purposes\n",
    "    def forward(self, users, items):\n",
    "        # Need to fit bias factors\n",
    "#         print(\"Forward\")\n",
    "        return torch.mm(self.user_factors(users),torch.transpose(self.item_factors(items),0,1))\n",
    "    \n",
    "    def get_batch(self,batch_size,ratings):\n",
    "        # Sort our data and scramble it\n",
    "        rows, cols = ratings.shape\n",
    "        p = np.random.permutation(rows)\n",
    "\n",
    "        # create batches\n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < rows:\n",
    "            batch = p[sindex:eindex]\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= rows:\n",
    "            batch = range(sindex,rows)\n",
    "            yield batch \n",
    "    \n",
    "    def run_test(self,batch_size,ratings_test):\n",
    "\n",
    "        predictionsArray = []\n",
    "        losses = []\n",
    "        print(\"Number Batches: {}\".format(ratings_test.shape[0]/batch_size))\n",
    "        for i,batch in tqdm(enumerate(model.get_batch(batch_size,ratings_test))):\n",
    "            print(i)\n",
    "            if self.useCUDA:\n",
    "                interactions = Variable(torch.cuda.FloatTensor(ratings_test[batch, :].toarray()),volatile = True)\n",
    "                rows = Variable(torch.cuda.LongTensor(batch), volatile = True)\n",
    "                cols = Variable(torch.cuda.LongTensor(np.arange(ratings_test.shape[1])), volatile = True)               \n",
    "            else:\n",
    "                interactions = Variable(torch.FloatTensor(ratings_test[batch, :].toarray()))\n",
    "                rows = Variable(torch.LongTensor(batch))\n",
    "                cols = Variable(torch.LongTensor(np.arange(ratings_test.shape[1])))\n",
    "\n",
    "            # Predict and calculate loss\n",
    "            predictions = self(rows, cols)\n",
    "            # predictions = self.predict(rows,cols)\n",
    "#              print(type(predictions))\n",
    "            predictionsArray.append(predictions.data.cpu().numpy())\n",
    "            # print(type(self.loss_func(predictions, interactions)))\n",
    "            losses.append(self.loss_func(predictions, interactions).data.cpu().numpy())\n",
    "\n",
    "            # del interactions\n",
    "            # del rows\n",
    "            # del cols\n",
    "        return predictionsArray, losses\n",
    "    \n",
    "    def run_epoch(self,batch_size, ratings):\n",
    "        for i,batch in tqdm(enumerate(self.get_batch(batch_size, ratings))):\n",
    "            # Set gradients to zero\n",
    "            self.reg_loss_func.zero_grad()\n",
    "\n",
    "#             print(type(batch))\n",
    "            # Turn data into variables\n",
    "            if self.useCUDA:\n",
    "#                 print(\"using cuda\")\n",
    "                interactions = Variable(torch.cuda.FloatTensor(ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.cuda.LongTensor(batch))\n",
    "                cols = Variable(torch.cuda.LongTensor(np.arange(ratings.shape[1])))               \n",
    "            else:\n",
    "                interactions = Variable(torch.FloatTensor(ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.LongTensor(batch))\n",
    "                cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "\n",
    "#             print(type(rows))\n",
    "#             print(type(cols))\n",
    "            # Predict and calculate loss\n",
    "            predictions = model(rows, cols)\n",
    "#             print(predictions)\n",
    "            self.currentLoss = self.loss_func(predictions, interactions)\n",
    "\n",
    "            # Backpropagate\n",
    "            self.currentLoss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            self.reg_loss_func.step()\n",
    "    \n",
    "    def train(self, numEpochs, batch_size, ratings,learningRate):\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.reg_loss_func = torch.optim.SGD(model.parameters(), lr=learningRate, weight_decay=1e-3)\n",
    "        for i in range(numEpochs):\n",
    "            print(i)\n",
    "            self.run_epoch(batch_size,ratings)\n",
    "            \n",
    "    def convertArryToVariable(self, array):\n",
    "        if self.useCUDA:\n",
    "            return Variable(torch.cuda.LongTensor(array))\n",
    "        else:\n",
    "            return Variable(torch.LongTensor(array))\n",
    "\n",
    "\n",
    "    \n",
    "    def convertLillMatrixToVariable(self,lillMatrix):\n",
    "        if self.useCUDA:\n",
    "            if lillMatrix.shape[0] == 1:\n",
    "                # we have a single matrix\n",
    "                return Variable(torch.cuda.LongTensor(lillMatrix.toarray()))\n",
    "            else:\n",
    "                return Variable(torch.cuda.LongTensor(lillMatrix.toarray()))\n",
    "        else:\n",
    "            if lillMatrix.shape[0] == 1:\n",
    "                # we have a single matrix\n",
    "                return Variable(torch.LongTensor(lillMatrix.toarray()))\n",
    "            else:\n",
    "                return Variable(torch.LongTensor(lillMatrix.toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "CUDA is being used\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Model\")\n",
    "model = MatrixFactorization(ratings.shape[0], ratings.shape[1], n_factors=2,useBias = False)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 1\n",
    "BATCH_SIZE = 1000 #50\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Model\")\n",
    "model.train(EPOCH,BATCH_SIZE,ratings,LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loss: Variable containing:\n",
      " 1.9848\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Loss: {}\".format(model.getLoss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Task 1:\n",
    "\n",
    "loadPrevResults = False\n",
    "loadSavedMeans = False\n",
    "\n",
    "EPOCH = 1 # Number of Epochs to train for\n",
    "BATCH_SIZE = 1000 #50\n",
    "LRs = [0.001, 0.01, 0.1] # array of learning rates to test\n",
    "\n",
    "FileNames = [\"r4\"]\n",
    "if loadPrevResults:\n",
    "    LambdaMeanLossResultsFrame = pd.read_csv('Task1_LambdaMeanLossResults_{}Epochs.csv'.format(EPOCH),index_col=0)\n",
    "\n",
    "    print(LambdaMeanLossResultsFrame)\n",
    "else:\n",
    "    LambdaMeanLossResultsFrame = pd.DataFrame(index=[\"r1\",\"r2\",\"r3\",\"r4\",\"r5\"], columns=['0.001','0.01','0.1'])\n",
    "    print(LambdaMeanLossResultsFrame)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Running Exmperiment on file ids {}\".format(FileNames))\n",
    "for fileName in FileNames:\n",
    "\n",
    "    print(\"Starting Building model for cross validation {}\".format(fileName))\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    print(\"Loading Data\")\n",
    "    df_train = pd.read_csv('ml-10M100K/'+fileName+'.train', sep='::', names=names,engine='python')\n",
    "    print(\"Loaded train data\")\n",
    "    df_test = pd.read_csv('ml-10M100K/'+fileName+'.test', sep='::', names=names,engine='python')\n",
    "    print(\"Loaded Data\")\n",
    "\n",
    "    ratings = get_movielens_ratings(df_train)\n",
    "    print(ratings.shape)\n",
    "\n",
    "    test_ratings = get_movielens_ratings(df_test)\n",
    "    print(test_ratings.shape)\n",
    "\n",
    "    print(\"Prepared the data\")\n",
    "\n",
    "\n",
    "    print(\"Creating Model\")\n",
    "    model = MatrixFactorization(ratings.shape[0], ratings.shape[1], n_factors=2,useBias = False)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    print(\"Running the training\")\n",
    "\n",
    "    print(\"Learining Rates tested: {}\".format(LRs))\n",
    "    for LR in LRs:\n",
    "        print(\"Training Model\")\n",
    "        print(\"Number iterations Per Epoch: {}\".format(ratings.shape[0]/BATCH_SIZE))\n",
    "        model.train(EPOCH,BATCH_SIZE,ratings,LR)\n",
    "\n",
    "        print(\"Model Loss: {}\".format(model.getLoss()))\n",
    "        print(\"Running Test\")\n",
    "        predictions, losses = model.run_test(10,test_ratings)\n",
    "\n",
    "        print(len(predictions))\n",
    "        print(np.mean(losses))\n",
    "\n",
    "        LambdaMeanLossResultsFrame.loc[fileName][str(LR)] = np.mean(losses)\n",
    "        print(LambdaMeanLossResultsFrame)\n",
    "\n",
    "        LambdaMeanLossResultsFrame.to_csv('Task1_LambdaMeanLossResults_{}Epochs.csv'.format(EPOCH))\n",
    "\n",
    "    LambdaMeanLossResultsFrame.to_csv('Task1_LambdaMeanLossResults_{}Epochs.csv'.format(EPOCH))\n",
    "\n",
    "LambdaMeanLossResultsFrame.to_csv('Task1_LambdaMeanLossResults_{}Epochs.csv'.format(EPOCH))\n",
    "\n",
    "print(LambdaMeanLossResultsFrame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
