{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import *\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = []\n",
    "for file in os.listdir(\"data/train_1\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        fileNames.append(file)\n",
    "# fileNamesDF = pd.DataFrame(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9e4530e89a444f84ce1e0822899b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=115), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#only take certain artist so that the probabilities aren't basically all false when doing the tupples\n",
    "minNumPaintingsPerArtist = 150\n",
    "\n",
    "# #for each artist, only take n of their paintings\n",
    "numPaintingsPerAuthor = 100\n",
    "\n",
    "\n",
    "trainInfo = pd.read_csv('data/train_info.csv')\n",
    "mostPopularArtists = trainInfo['artist'].value_counts()[trainInfo['artist'].value_counts() > minNumPaintingsPerArtist]\n",
    "\n",
    "trainInfo = trainInfo[trainInfo['filename'].isin(fileNames)]\n",
    "fileNamesDFAll = trainInfo[trainInfo['artist'].isin(mostPopularArtists.index)]\n",
    "\n",
    "\n",
    "fileNamesDF = pd.DataFrame()\n",
    "for artist in tqdm(mostPopularArtists.index):\n",
    "    fileNamesDF = fileNamesDF.append(trainInfo[trainInfo['artist'] == artist][:numPaintingsPerAuthor])\n",
    "    \n",
    "fileNamesDF = fileNamesDF['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the all_data_info for the dataset we are using\n",
    "allInfo = pd.read_csv('data/all_data_info.csv')\n",
    "allInfo = allInfo[allInfo['new_filename'].isin(fileNamesDF)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDF = pd.DataFrame(allInfo['new_filename'])\n",
    "featuresDF['pixelsx'] = allInfo['pixelsx']\n",
    "featuresDF['pixelsy'] = allInfo['pixelsy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSeries(series, maxNum):\n",
    "    series = series/maxNum\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurizeImage(filename):\n",
    "    # Extract the features from the actual image\n",
    "    jpgfile = Image.open(\"data/train_1/\" + filename)\n",
    "#     print(jpgfile)\n",
    "    \n",
    "    bands = jpgfile.getbands()\n",
    "    if bands[0] == 'L':\n",
    "        # grayscale image\n",
    "        imageDF = pd.DataFrame(list(jpgfile.getdata()),columns=['grayscale'])\n",
    "#         imageDF['grayscale'] = normalizeSeries(imageDF['grayscale',])\n",
    "    elif len(bands) == 4:\n",
    "        #get red, green and blue chanels \n",
    "        imageDF = pd.DataFrame(list(jpgfile.getdata()),columns=['red','green','blue','alpha'])\n",
    "        imageDF['red'] = normalizeSeries(imageDF['red'],255)\n",
    "        imageDF['green'] = normalizeSeries(imageDF['green'],255)\n",
    "        imageDF['blue'] = normalizeSeries(imageDF['blue'],255)  \n",
    "        imageDF['alpha'] = normalizeSeries(imageDF['alpha'],255)  \n",
    "    elif len(bands) == 3:\n",
    "        #get red, green and blue chanels \n",
    "        imageDF = pd.DataFrame(list(jpgfile.getdata()),columns=['red','green','blue'])\n",
    "        imageDF['red'] = normalizeSeries(imageDF['red'],255)\n",
    "        imageDF['green'] = normalizeSeries(imageDF['green'],255)\n",
    "        imageDF['blue'] = normalizeSeries(imageDF['blue'],255)  \n",
    "    else:\n",
    "        imageDF = pd.DataFrame(list(jpgfile.getdata()))\n",
    "        print(bands)\n",
    "        return imageDF, bands\n",
    "\n",
    "    return imageDF.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    74,    110,    129,    141,    142,    149,    159,    178,\n",
       "               201,    213,\n",
       "            ...\n",
       "            102113, 102402, 102551, 102565, 102862, 102888, 103030, 103049,\n",
       "            103051, 103066],\n",
       "           dtype='int64', length=4170)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imageFeaturesDF = pd.DataFrame(index=featuresDF.index,columns=['features']) \n",
    "print(imageFeaturesDF.index)\n",
    "for row in tqdm(list(featuresDF.index)):\n",
    "    imageFeatures = featurizeImage(featuresDF.loc[row]['new_filename'])\n",
    "    imageFeaturesDF.loc[row]['features'] = imageFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFeaturesDF.to_csv('image_features_extracted5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDF['imgFeatures'] = imageFeaturesDF['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareImages(img1, img2):\n",
    "    \n",
    "    diffx = np.abs(img1['pixelsx']-img2['pixelsx']) / (img1['pixelsx'] + img2['pixelsx'])\n",
    "    diffy = np.abs(img1['pixelsy']-img2['pixelsy']) / (img1['pixelsy'] + img2['pixelsy'])\n",
    "    \n",
    "    diffSize = (diffx + diffy)/2\n",
    "    \n",
    "    img1Features = img1['imgFeatures']\n",
    "    img2Features = img2['imgFeatures']\n",
    "    \n",
    "    imgFeatureScore = 0\n",
    "    \n",
    "    if (len(img1Features) == len(img2Features)):\n",
    "        imgFeatureDiffs = np.abs(img1Features - img2Features)\n",
    "        imgFeatureScore = sum(imgFeatureDiffs)\n",
    "        score = (diffSize+imgFeatureScore)/2\n",
    "    else:\n",
    "        score = (diffSize+imgFeatureScore)/2\n",
    "\n",
    "   \n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePrediction(score,threshold):\n",
    "    if score > threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def generatePredictions(scores,threshold):\n",
    "    predictions = []\n",
    "    for curScore in tqdm(scores,leave=False):\n",
    "        predictions.append(generatePrediction(curScore,threshold))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeStats(truth,predictions):\n",
    "    \n",
    "    accuracy = (predictions == truth).sum()/len(predictions == truth)\n",
    "    \n",
    "    trues = [True for _ in range(len(predictions))]\n",
    "    falses = [False for _ in range(len(predictions))]\n",
    "\n",
    "    predictionsTrue = [predictions[i] == trues[i] for i in range(len(predictions))]\n",
    "    predictionsFalse = [predictions[i] == falses[i] for i in range(len(predictions))]\n",
    "    \n",
    "    \n",
    "    truthTrue = [truth[i] == trues[i] for i in range(len(truth))]\n",
    "    truthFalse = [truth[i] == falses[i] for i in range(len(truth))]\n",
    "    \n",
    "#     print(len(predictions))\n",
    "    truePos = np.sum([predictions[i] == True and truthTrue[i] == True for i in range(len(predictionsTrue))])\n",
    "#     print(truePos.sum())\n",
    "    trueNeg = np.sum([predictions[i] == False and truthTrue[i] == False for i in range(len(predictionsFalse))])\n",
    "    falsePos = np.sum([predictions[i] == True and truthTrue[i] == False for i in range(len(predictionsTrue))])\n",
    "    falseNeg = np.sum([predictions[i] == False and truthTrue[i] == True for i in range(len(predictionsFalse))])\n",
    "    \n",
    "    return accuracy, truePos, trueNeg, falsePos, falseNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainThreshold(featuresTrain,maxNumIterations = 100,initialProb = 0.5, increaseRate = 0.001):\n",
    "    \n",
    "    probThreshold = initialProb\n",
    "    prevAccuracy = 0\n",
    "\n",
    "    for i in tqdm(range(maxNumIterations),leave=False):\n",
    "        # the score represents how similar two images are\n",
    "\n",
    "        scores = []\n",
    "        iloc1 = featuresTrain.sample(frac=0.5).index\n",
    "        iloc2 = featuresTrain.sample(frac=0.5).index\n",
    "        # print(len(iloc2))\n",
    "        # print(nTrials)\n",
    "\n",
    "        for i, loc in tqdm(enumerate(iloc1),leave=False):\n",
    "            scores.append(compareImages(featuresTrain.loc[loc],featuresTrain.loc[iloc2[i]]))\n",
    "\n",
    "        filenames1 = featuresTrain.loc[iloc1]['new_filename'].values\n",
    "        filenames2 = featuresTrain.loc[iloc2]['new_filename'].values\n",
    "\n",
    "\n",
    "        truth = trainInfo[trainInfo['filename'].isin(filenames1)]['artist'].values == trainInfo[trainInfo['filename'].isin(filenames2)]['artist'].values\n",
    "        predictions = generatePredictions(scores,probThreshold)\n",
    "\n",
    "        #compute true positive -\n",
    "        accuracy, tp, tn, fp, fn = computeStats(truth,predictions)\n",
    "       \n",
    "        if (accuracy < prevAccuracy):\n",
    "            print(\"peak accuracy\")\n",
    "            return probThreshold, prevAccuracy,tp, tn, fp, fn\n",
    "        \n",
    "        probThreshold += increaseRate\n",
    "    \n",
    "    return probThreshold, accuracy, tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDevAcc(featuresTrain,probability):\n",
    "\n",
    "    # the score represents how similar two images are\n",
    "    scores = []\n",
    "    iloc1 = featuresTrain.sample(frac=0.5).index\n",
    "    iloc2 = featuresTrain.sample(frac=0.5).index\n",
    "\n",
    "    # print(len(iloc2))\n",
    "    # print(nTrials)\n",
    "\n",
    "    for i, loc in tqdm(enumerate(iloc1),leave=False):\n",
    "        scores.append(compareImages(featuresTrain.loc[loc],featuresTrain.loc[iloc2[i]]))\n",
    "\n",
    "    filenames1 = featuresTrain.loc[iloc1]['new_filename'].values\n",
    "    filenames2 = featuresTrain.loc[iloc2]['new_filename'].values\n",
    "\n",
    "\n",
    "    truth = trainInfo[trainInfo['filename'].isin(filenames1)]['artist'].values == trainInfo[trainInfo['filename'].isin(filenames2)]['artist'].values\n",
    "    predictions = generatePredictions(scores,probability)\n",
    "\n",
    "    #compute stats\n",
    "    accuracy, tp, tn, fp, fn = computeStats(truth,predictions)\n",
    "    return accuracy, tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nTrainFraction = 0.6\n",
    "nDevFraction = 0.4\n",
    "\n",
    "thresholds = []\n",
    "devAccuracies = []\n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "\n",
    "numberSamples = 10\n",
    "for i in tqdm(range(numberSamples)):\n",
    "    featuresTrain = featuresDF.sample(frac=nTrainFraction)\n",
    "    featuresDev = featuresDF.drop(featuresTrain.index)\n",
    "#     featuresTest = featuresDF.drop(featuresDev.index).drop(featuresTrain.index).sample(n=nTest)\n",
    "    learnedThreshold, trainAccuracy, traintp, traintn, trainfp, trainfn = trainThreshold(featuresTrain,50,0.5,0.01)\n",
    "    thresholds.append((learnedThreshold,trainAccuracy,traintp, traintn, trainfp, trainfn))\n",
    "    meanDevAccuracy = 0\n",
    "    accuraciesDev = []\n",
    "    for i in range(10):\n",
    "        acc, ctp, ctn, cfp, cfn = computeDevAcc(featuresDev,learnedThreshold)\n",
    "        accuraciesDev.append(acc)\n",
    "        tp.append(ctp)\n",
    "        tn.append(ctn)\n",
    "        fp.append(cfp)\n",
    "        fn.append(cfn)\n",
    "    meanDevAccuracy = np.mean(accuraciesDev)\n",
    "    devAccuracies.append(meanDevAccuracy)\n",
    "    \n",
    "print(thresholds)\n",
    "print(devAccuracies)\n",
    "print(tp)\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(tp))\n",
    "print(np.mean(tn))\n",
    "print(np.mean(fp))\n",
    "print(np.mean(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(devAccuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(tn)/(np.mean(fp)+np.mean(tn)) #true negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(tp)+np.mean(tn))/(np.mean(fp)+np.mean(fn) + np.mean(tp)+np.mean(tn)) # accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
