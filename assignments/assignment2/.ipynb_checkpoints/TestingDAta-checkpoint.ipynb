{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1M = pd.read_csv('train1M.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>integer_1</th>\n",
       "      <th>integer_2</th>\n",
       "      <th>integer_3</th>\n",
       "      <th>integer_4</th>\n",
       "      <th>integer_5</th>\n",
       "      <th>integer_6</th>\n",
       "      <th>integer_7</th>\n",
       "      <th>integer_8</th>\n",
       "      <th>integer_9</th>\n",
       "      <th>...</th>\n",
       "      <th>categorical_18</th>\n",
       "      <th>categorical_19</th>\n",
       "      <th>categorical_20</th>\n",
       "      <th>categorical_21</th>\n",
       "      <th>categorical_22</th>\n",
       "      <th>categorical_23</th>\n",
       "      <th>categorical_24</th>\n",
       "      <th>categorical_25</th>\n",
       "      <th>categorical_26</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5edd90de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e12ce348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c3dc6cef</td>\n",
       "      <td>49045073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19811.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>ea9a246c</td>\n",
       "      <td>731c3655</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2931.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0f4a15b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0014c32a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40698.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>281769c2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d4703ebd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>aee52b6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>f54016b9</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>ff3ce4c0</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>be7c41b4</td>\n",
       "      <td>d691765a</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>d1d45fc5</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  integer_1  integer_2  integer_3  integer_4  integer_5  integer_6  \\\n",
       "19       0        7.0        102        NaN        3.0      780.0       15.0   \n",
       "135      0        NaN          0       17.0        3.0    19811.0        NaN   \n",
       "177      0        NaN          1        5.0        4.0     2931.0       36.0   \n",
       "250      0        NaN          0        NaN        0.0    40698.0      963.0   \n",
       "329      1        NaN         23       83.0        2.0        NaN        NaN   \n",
       "\n",
       "     integer_7  integer_8  integer_9  ...   categorical_18  categorical_19  \\\n",
       "19         7.0       15.0       15.0  ...         5edd90de             NaN   \n",
       "135        0.0        3.0       54.0  ...         b04e4670        21ddcdc9   \n",
       "177        2.0        6.0       62.0  ...         0f4a15b0             NaN   \n",
       "250        0.0        2.0       23.0  ...         281769c2             NaN   \n",
       "329        0.0        2.0        2.0  ...         f54016b9        21ddcdc9   \n",
       "\n",
       "     categorical_20  categorical_21 categorical_22 categorical_23  \\\n",
       "19              NaN        e12ce348            NaN       c3dc6cef   \n",
       "135        5840adea        60f6221e            NaN       32c7478e   \n",
       "177             NaN        0014c32a            NaN       3a171ecb   \n",
       "250             NaN        d4703ebd            NaN       32c7478e   \n",
       "329        5840adea        ff3ce4c0       c9d4222a       be7c41b4   \n",
       "\n",
       "    categorical_24 categorical_25 categorical_26 Index  \n",
       "19        49045073            NaN            NaN    19  \n",
       "135       43f13e8b       ea9a246c       731c3655   135  \n",
       "177       3b183c5c            NaN            NaN   177  \n",
       "250       aee52b6f            NaN            NaN   250  \n",
       "329       d691765a       e8b83407       d1d45fc5   329  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1M.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Histograms and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateSummaryStatsAndHists(train1M):\n",
    "    SummaryStats = pd.DataFrame()\n",
    "    for col in train1M.columns:\n",
    "        if (col != 'label' and col != 'Index' and col != 'Unnamed: 0'):\n",
    "\n",
    "            train1M[col][train1M['label'] == 0].value_counts().plot(kind='hist',title=col, bins=100,label='0s')\n",
    "            train1M[col][train1M['label'] == 1].value_counts().plot(kind='hist',title=col, bins=100,label='1s')\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.savefig(col)\n",
    "            plt.show()\n",
    "            plt.gcf().clear()\n",
    "            if (train1M[col].dtype != 'O'):\n",
    "                SummaryStats[col] = train1M[col].describe()   \n",
    "    # SummaryStats.head()\n",
    "    SummaryStats.to_csv('integerStats.csv')\n",
    "    return SummaryStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SummaryStats = generateSummaryStatsAndHists(train1M)\n",
    "SummaryStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1M['integer_1'][train1M['label'] == 0].value_counts().plot(kind='hist',title='integer_1', bins=100,label='0s')\n",
    "train1M['integer_1'][train1M['label'] == 1].value_counts().plot(kind='hist',title='integer_1', bins=100,label='1s')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Normalization and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train1M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train1M[train1M[train1M.columns[1:14]] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keeping the following categorical features:\n",
    "# - 9 Because it has 3 distinct peaks\n",
    "# - 6 because both peaks and >9 points\n",
    "\n",
    "# Dropping the following categorical features because \n",
    "# - Categorical_1 b/c they all have only 1 column for most features \n",
    "# - 3\n",
    "# - 4 \n",
    "# - 8\n",
    "# - 10\n",
    "# - 12\n",
    "# - 16\n",
    "# - 19\n",
    "# - 21\n",
    "# - 24\n",
    "# - 26\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder = OneHotEncoder()\n",
    "# encoder.fit_transform(train1M[train1M.columns[14]])\n",
    "train1M[train1M.columns[14]].dtype\n",
    "\n",
    "def generateCategoricalData(train1M):\n",
    "    #change to categorical\n",
    "    for col in train1M.columns[14:40]:\n",
    "        train1M[col] = train1M[col].astype('category')\n",
    "        # add the dummy category\n",
    "        train1M[col].cat.add_categories(new_categories = 'Dummy',inplace = True)\n",
    "        categories = pd.Series(train1M[col].cat.categories)\n",
    "        categories.to_csv(str(col)+'_features.csv',header = False)\n",
    "        #save the categories for each column\n",
    "        #then we can set the categegories for each column\n",
    "        # and when we get dummies from pandas we have a one hot encoding that is consistent accross\n",
    "        # -> get_dummies() method does one hot encoding\n",
    "        \n",
    "generateCategoricalData(train1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         integer_1     integer_2     integer_3     integer_4     integer_5  \\\n",
      "mean -9.846092e-15  1.489631e-15 -4.199304e-15  7.936985e-15 -5.790918e-17   \n",
      "std   1.000000e+00  1.000001e+00  1.000000e+00  1.000000e+00  1.000001e+00   \n",
      "\n",
      "         integer_6     integer_7     integer_8     integer_9    integer_10  \\\n",
      "mean -4.077688e-17 -1.721416e-14 -1.276412e-16  7.152975e-15  1.552617e-14   \n",
      "std   1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
      "\n",
      "        integer_11    integer_12    integer_13  \n",
      "mean -1.178304e-13  1.435046e-14 -1.068410e-14  \n",
      "std   1.000001e+00  1.000001e+00  1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "def preProcessData(train1M):\n",
    "    train1M[train1M.columns[1:14]] = train1M[train1M.columns[1:14]].fillna(0)\n",
    "    train1M[train1M.columns[14:40]] = train1M[train1M.columns[14:40]].fillna('Dummy')\n",
    "    train1M[train1M.columns[1:14]] = train1M[train1M.columns[1:14]].replace(-1,0)\n",
    "\n",
    "def dropFeature(series,feature):\n",
    "    \n",
    "    for index, value in series.iteritems():\n",
    "        if (value == feature):\n",
    "#             print('index: ', index, 'value: ', value)\n",
    "            series = series.drop(index)\n",
    "            return series            \n",
    "    return -1\n",
    "\n",
    "def preProcessInts(train1M):\n",
    "    # mean-center and unit variance the integers\n",
    "    trainingMeanSTD = pd.read_csv('training_stats_integers.csv',index_col=0)\n",
    "    print(trainingMeanSTD.head())\n",
    "#     for col in train1M.columns: \n",
    "        \n",
    "        \n",
    "    \n",
    "    train1M[train1M.columns[1:14]] = scale(train1M[train1M.columns[1:14]])\n",
    "\n",
    "preProcessData(train1M)\n",
    "\n",
    "preProcessInts(train1M)\n",
    "\n",
    "\n",
    "featuresToKeep = pd.Series(data = train1M.columns)\n",
    "# print(featuresToKeep)\n",
    "featuresToKeep = dropFeature(featuresToKeep,'Index')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'label')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_1')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_3')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_4')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_5')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_8')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_10')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_12')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_16')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_19')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_21')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_24')\n",
    "featuresToKeep = dropFeature(featuresToKeep,'categorical_26')\n",
    "\n",
    "featuresToKeep.to_csv('features.txt',header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now that I have my kept features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #generate the list of features and assign an integer value to them (the index is the integer value)\n",
    "# for col in train1M.columns[14:40]:\n",
    "#     print(train1M[col].cat.categories)\n",
    "#     print(train1M[col].cat.codes)\n",
    "#     pd.Series(train1M[col].cat.categories, index=train1M[col].cat.codes).to_csv(str(col)+'_features.csv',header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in train1M.columns[14:40]:\n",
    "    # load the current Feature spaces\n",
    "    curFeatures = pd.read_csv(str(col) + \"_features.csv\",header = None,index_col = 0)\n",
    "    \n",
    "    pd.concat([train1M, pd.get_dummies(train1M[col],prefix=['encoded'],sparse=True)])\n",
    "    \n",
    "#     print(\"done 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1M['categorical_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessIntsAndSave(train1M,fileName):\n",
    "    # mean-center and unit variance the integers\n",
    "#     trainingMeanSTD = pd.read_csv('training_stats_integers.csv',index_col=0)\n",
    "#     print(trainingMeanSTD.head())\n",
    "    curScaler = StandardScaler()\n",
    "    curScaler.fit(train1M[train1M.columns[1:14]])\n",
    "    joblib.dump(curScaler, fileName) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMeanAndSTD(series):\n",
    "\n",
    "    return pd.DataFrame(data = [series.mean(), series.std()], index = ['mean','std'])\n",
    "\n",
    "getMeanAndSTD(train1M[train1M.columns[1:14]]).to_csv('training_stats_integers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01140292 -0.0595101  -0.32714324 ... -0.31593225 -0.09583118\n",
      "  -0.24232319]\n",
      " [-0.27098801 -0.01190302 -0.32714324 ... -0.51150991 -0.09583118\n",
      "  -0.24232319]\n",
      " [-0.26844306 -0.04550802 -0.207158   ... -0.31593225 -0.09583118\n",
      "  -0.1005595 ]\n",
      " ...\n",
      " [-0.27098801 -0.05670968 -0.44712848 ...  1.0531114  -0.09583118\n",
      "  -0.31320503]\n",
      " [ 0.28381149 -0.03990718 -0.44712848 ... -0.12035458 -0.09583118\n",
      "  -0.31320503]\n",
      " [ 1.86422658 -0.05390927 -0.68709897 ... -0.51150991 -0.09583118\n",
      "  -0.45496872]]\n"
     ]
    }
   ],
   "source": [
    "preProcessIntsAndSave(train1M[train1M.columns[1:14]],'scalerPickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = joblib.load('scalerPickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "scaler.transform(train1M[train1M.columns[1:14]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1M[train1M.columns[1:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
