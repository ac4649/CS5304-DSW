{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import k_means\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ks(path_to_ks):\n",
    "    ks = pd.read_csv(path_to_ks, names=['k'], dtype=np.int32)\n",
    "    return ks['k'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(output, y):\n",
    "    assert type(output) == np.ndarray\n",
    "    assert output.ndim == 1\n",
    "    assert output.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adrien Cogny - Assignment 1 for Data Science in the Wild at Cornell Tech\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def load_labels(pathtoLabels):\n",
    "    DF = pd.read_csv(pathtoLabels,header=None);\n",
    "    return DF[0];\n",
    "\n",
    "def load_training_data():\n",
    "    dataSet = fetch_rcv1(subset='train')\n",
    "\n",
    "    return dataSet.data, dataSet.target, dataSet.sample_id\n",
    "\n",
    "def load_validation_data(validationData):\n",
    "\n",
    "    # This is taken from the homework FAQ and modified slightly.\n",
    "    test_data = fetch_rcv1(subset='test')\n",
    "    ids = pd.read_csv(validationData)\n",
    "    mask = np.isin(test_data.sample_id, ids)\n",
    "    validation_data = test_data.data[mask]\n",
    "    validation_target = test_data.target[mask]\n",
    "    return validation_data, validation_target, test_data\n",
    "\n",
    "class CS5304KNNClassifier():\n",
    "\n",
    "    numNeighbors = 5;\n",
    "\n",
    "    classifier = None;\n",
    "    # def __init__(self,):\n",
    "    #     # Initialization of the knn classifier should be done here\n",
    "    #     self.classifier = NearestNeighbors(n_neighbors=self.numNeighbors);        \n",
    "    #     return\n",
    "    def __init__(self,n_neighbors = None):\n",
    "        if (type(n_neighbors) == int):\n",
    "            self.numNeighbors = n_neighbors;\n",
    "        self.classifier = KNeighborsClassifier(n_neighbors=self.numNeighbors,algorithm='brute');        \n",
    "\n",
    "    def train(self,fitX, fitY):\n",
    "        #in the fitX, fitY sparce matrix, the index of the element is in indptr\n",
    "\n",
    "        fitXIndexElem = fitX.indptr;\n",
    "        fitYIndexElem = fitY.indptr;\n",
    "\n",
    "        fitXelemDF = pd.Series(data=fitX.indptr[1:])\n",
    "        fitYelemDF = pd.Series(data=fitY.indptr[1:])\n",
    "        # print(fitXelemDF);\n",
    "        # print(fitYelemDF);\n",
    "\n",
    "\n",
    "        dataArray = fitX.toarray()\n",
    "        dataDF = pd.DataFrame(data=dataArray,index=fitXelemDF)\n",
    "        # print(dataDF)\n",
    "\n",
    "        targetArray = fitY.toarray()\n",
    "        targetDF = pd.DataFrame(data=targetArray,index=fitYelemDF)\n",
    "        # print(targetDF)\n",
    "\n",
    "        self.classifier.fit(dataDF,targetDF);\n",
    "        return\n",
    "\n",
    "    def predict(self,predictX):\n",
    "        dataArray = predictX.toarray()\n",
    "        dataDF = pd.DataFrame(data=dataArray)\n",
    "        return self.classifier.predict(predictX)\n",
    "\n",
    "    def score(self,data,labels):\n",
    "        dataArray = data.toarray()\n",
    "        dataDF = pd.DataFrame(data=dataArray)\n",
    "\n",
    "        predictArray = labels.toarray()\n",
    "        labelsDF = pd.DataFrame(data=predictArray)\n",
    "\n",
    "        return self.classifier.score(dataDF,labelsDF)\n",
    "\n",
    "\n",
    "\n",
    "class CS5304NBClassifier():\n",
    "\n",
    "    classifier = None;\n",
    "    def __init__(self, alphanew = 1.25):\n",
    "        self.classifier = BernoulliNB(alpha = alphanew)\n",
    "        return\n",
    "    \n",
    "    def train(self,fitX, fitY):\n",
    "        \n",
    "        self.classifier.fit(fitX,fitY.todense())\n",
    "        return\n",
    "\n",
    "    def predict(self,predictX):\n",
    "        dataArray = predictX.toarray()\n",
    "        dataDF = pd.DataFrame(data=dataArray)\n",
    "        return self.classifier.predict(predictX)\n",
    "\n",
    "    def score(self,data,labels):\n",
    "        return self.classifier.score(data,labels.todense())\n",
    "\n",
    "class CS5304KMeansClassifier():\n",
    "    classifier = None;\n",
    "#     centroids = None;\n",
    "    numClusters = 2;\n",
    "    def __init__(self, n_clusters=2, init='k-means++'):\n",
    "        self.numClusters = n_clusters\n",
    "        return\n",
    "    \n",
    "    def train(self,fitX, fitY):\n",
    "        dataset = pd.DataFrame(data = fitX.toarray())\n",
    "        dataset['label'] = fitY.todense()\n",
    "        print(dataset.head(20))\n",
    "#         dataset.info(memory_usage='deep')\n",
    "        \n",
    "#         meanData = dataset[dataset['label'] == 1].drop(columns = ['label']).mean()\n",
    "#         meanOtherData = dataset[dataset['label'] == 0].drop(columns = ['label']).mean()\n",
    "        preClassifier = KMeans(n_clusters=1)\n",
    "        preClassifier.fit(dataset[dataset['label'] == 1].drop(columns = ['label']))\n",
    "        \n",
    "        meanCentroid = pd.Series(preClassifier.cluster_centers_[0])\n",
    "#         print(meanCentroid);\n",
    "        \n",
    "        preClassifier.fit(dataset[dataset['label'] == 0].drop(columns = ['label']))\n",
    "        meanOtherDataCentroid = pd.Series(preClassifier.cluster_centers_[0])\n",
    "#         print(meanOtherDataCentroid);\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         print(meanData)\n",
    "#         print(meanData.shape)\n",
    "#         print(meanOtherData)\n",
    "#         print(meanOtherData.shape)\n",
    "        \n",
    "        del dataset # memory drain so delete it\n",
    "        \n",
    "        initClusters = pd.concat([meanOtherDataCentroid, meanCentroid], axis = 1);\n",
    "        \n",
    "        print(initClusters.head())\n",
    "        print(initClusters.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.classifier = KMeans(n_clusters=self.numClusters, init=initClusters.T)\n",
    "\n",
    "        self.classifier.fit(fitX,fitY.todense())\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def predict(self,predictX):\n",
    "#         dataArray = predictX.toarray()\n",
    "#         dataDF = pd.DataFrame(data=dataArray)\n",
    "        return self.classifier.predict(predictX)\n",
    "\n",
    "    def score(self,data,labels):\n",
    "        predictedClusters = self.classifier.predict(data);\n",
    "        dataFrame = pd.DataFrame(data = predictedClusters, columns=['Predicted'])\n",
    "        dataFrame['actual'] = labels.todense()\n",
    "        dataFrame['predictedAccuracy'] = dataFrame['Predicted'] == dataFrame['actual']\n",
    "        \n",
    "        numItemsOfClass = (dataFrame['actual'] == 1).sum()\n",
    "        numItemsNotOfClass = (dataFrame['actual'] == 0).sum()\n",
    "        \n",
    "        truePositives = ((dataFrame['actual'] == 1) & (dataFrame['Predicted'] == 1)).sum()\n",
    "        falsePositives = ((dataFrame['actual'] == 0) & (dataFrame['Predicted'] == 1)).sum()\n",
    "        falseNegatives = ((dataFrame['actual'] == 1) & (dataFrame['Predicted'] == 0)).sum()\n",
    "        trueNegatives = ((dataFrame['actual'] == 0) & (dataFrame['Predicted'] == 0)).sum()\n",
    "        \n",
    "        Precision = truePositives / (truePositives + falsePositives)\n",
    "        Recall = truePositives / (truePositives + falseNegatives)\n",
    "        print(Precision)\n",
    "        print(Recall)\n",
    "        f1 = 1/((1/Precision) + (1/Recall))\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_labels = \"labels.txt\"\n",
    "path_to_ids = \"validation.txt\"\n",
    "path_to_ks = \"ks.txt\"\n",
    "label = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = load_ks(path_to_ks)\n",
    "labels = load_labels(path_to_labels)\n",
    "train_data, train_target, _ = load_training_data()\n",
    "eval_data, eval_target, _ = load_validation_data(path_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      4\n",
      "1      5\n",
      "2      7\n",
      "3     33\n",
      "4     59\n",
      "5     70\n",
      "6     83\n",
      "7     95\n",
      "8     98\n",
      "9    102\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scoresDF = pd.DataFrame(index=[i for i in range(1,21)],columns=[label for label in labels])\n",
    "for label in labels:    \n",
    "    print(label)\n",
    "    # Grade Ex. 1a\n",
    "    for k in range(1,21):\n",
    "#         print(k)\n",
    "        limit = 1000\n",
    "#         k = 15 # change this\n",
    "        knn = CS5304KNNClassifier(n_neighbors=k)\n",
    "        knn.train(train_data[:limit], train_target[:limit][:, label])\n",
    "        output = knn.predict(eval_data[:limit])\n",
    "        check_output(output,eval_target[:limit])\n",
    "    #     print(knn.score(eval_data[:limit],eval_target[:limit][:, label]))\n",
    "        scoresDF[label][k] = knn.score(eval_data[:limit],eval_target[:limit][:, label])\n",
    "\n",
    "scoresDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresDF.head(20)\n",
    "scoresDF.to_csv('scores_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresDF.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresDF.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresDF.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB Classification Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(label)\n",
    "# # nb = CS5304NBClassifier()\n",
    "# # nb.train(train_data, train_target[:, label])\n",
    "# # output = nb.predict(eval_data)\n",
    "# # check_output(output,eval_target)\n",
    "# # print(nb.score(eval_data,eval_target[:, label]))\n",
    "\n",
    "scoresNBDF = pd.DataFrame(index=[label for label in labels],columns=[i for i in np.arange(0.1, 2.0, 0.1)])\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    for alpha in np.arange(0.1, 2.0, 0.1):  \n",
    "#         print(alpha)\n",
    "        nb = CS5304NBClassifier(alpha)\n",
    "        nb.train(train_data, train_target[:, label])\n",
    "        output = nb.predict(eval_data)\n",
    "        check_output(output,eval_target)\n",
    "    #     print(nb.score(eval_data,eval_target[:, label]))\n",
    "        scoresNBDF[alpha][label] = nb.score(eval_data,eval_target[:, label])\n",
    "scoresNBDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoresNBDF.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresNBDF.T.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = CS5304KMeansClassifier()\n",
    "kmeans.train(train_data, train_target[:, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkingClassifier = kmeans.predict(train_data);\n",
    "pd.DataFrame(data=checkingClassifier)\n",
    "kmeans.score(eval_data,eval_target[:, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = kmeans.predict(eval_data)\n",
    "check_output(output,eval_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = kmeans.score(eval_data,eval_target[:, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
