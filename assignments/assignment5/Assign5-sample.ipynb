{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "from scipy.sparse import lil_matrix\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Loaded Train\n",
      "Loaded Test\n"
     ]
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "print(\"Loading Data\")\n",
    "df_train = pd.read_csv('ml-10M100K/r3.train', sep='::', names=names,engine='python')\n",
    "print(\"Loaded Train\")\n",
    "df_test = pd.read_csv('ml-10M100K/r3.test', sep='::', names=names,engine='python')\n",
    "print(\"Loaded Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1      122     5.0  838985046\n",
       "1        1      185     5.0  838983525\n",
       "2        1      231     5.0  838983392\n",
       "3        1      292     5.0  838983421\n",
       "4        1      316     5.0  838983392"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000044, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train.head()\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movielens_ratings(df):\n",
    "    n_users = max(df.user_id.unique())\n",
    "    n_items = max(df.item_id.unique())\n",
    "\n",
    "    interactions = lil_matrix( (n_users,n_items), dtype=float) #np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Training Data\n",
      "(71567, 65133)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Training Data\")\n",
    "ratings = get_movielens_ratings(df_train)\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Testing Data\n",
      "(42788, 65133)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Testing Data\")\n",
    "test_ratings = get_movielens_ratings(df_test)\n",
    "print(test_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_users, n_items, n_factors=5, useBias = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if torch.cuda.is_available(): # CHECK FOR CUDA AVAILABILITY\n",
    "            self.useCUDA = True\n",
    "            print(\"CUDA is being used\")\n",
    "        else:\n",
    "            print(\"CUDA not available, reverting to CPU\")\n",
    "            \n",
    "        if self.useCUDA: # IF IT IS AVAILABLE, USE IT\n",
    "            self.cuda() \n",
    "        \n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        # Also should consider fitting overall bias (self.mu term) and both user and item bias vectors\n",
    "        \n",
    "        ## Incorporation of Bias Term\n",
    "        if useBias:\n",
    "            self.user_bias = torch.nn.Embedding(n_users, 1, sparse = False)\n",
    "            self.item_bias = torch.nn.Embedding(n_itms, 1, sparse = False)\n",
    "        \n",
    "        \n",
    "        # Mu is 1x1, user_bias is 1xn_users. item_bias is 1xn_items\n",
    "        \n",
    "    def getLoss(self):\n",
    "        return self.currentLoss\n",
    "\n",
    "\n",
    "    currentLoss = 2\n",
    "    useCUDA = False\n",
    "#     loss_func = torch.nn.MSELoss()\n",
    "#     reg_loss_func = torch.optim.SGD(self.model.parameters(), lr=1e-6, weight_decay=1e-3)\n",
    "    \n",
    "    # For convenience when we want to predict a single user-item pair. \n",
    "    def predict(self, user, item):\n",
    "        # Need to fit bias factors\n",
    "#         prediction = self.user_bias(user) + self.item_bias(item)\n",
    "        #prediction += (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "        print(\"Predicting\")\n",
    "#         print(user)\n",
    "#         print(item)\n",
    "#         print(self.user_factors(user))\n",
    "#         print(self.item_factors(item))\n",
    "        return torch.mm(self.user_factors(user),torch.transpose(self.item_factors(item),0,1))\n",
    "#         return (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "    \n",
    "    \n",
    "#         return torch.dot(self.user_factors(user),self.item_factors(item))\n",
    "    \n",
    "    # Much more efficient batch operator. This should be used for training purposes\n",
    "    def forward(self, users, items):\n",
    "        # Need to fit bias factors\n",
    "        return torch.mm(self.user_factors(users),torch.transpose(self.item_factors(items),0,1))\n",
    "    \n",
    "    def get_batch(self,batch_size,ratings):\n",
    "        # Sort our data and scramble it\n",
    "        rows, cols = ratings.shape\n",
    "        p = np.random.permutation(rows)\n",
    "\n",
    "        # create batches\n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < rows:\n",
    "            batch = p[sindex:eindex]\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= rows:\n",
    "            batch = range(sindex,rows)\n",
    "            yield batch    \n",
    "    \n",
    "    def run_epoch(self,batch_size, ratings):\n",
    "        for i,batch in enumerate(self.get_batch(batch_size, ratings)):\n",
    "            # Set gradients to zero\n",
    "            self.reg_loss_func.zero_grad()\n",
    "\n",
    "            # Turn data into variables\n",
    "            if self.useCUDA:\n",
    "                interactions = Variable(torch.cuda.FloatTensor(ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.cuda.LongTensor(batch))\n",
    "                cols = Variable(torch.cuda.LongTensor(np.arange(ratings.shape[1])))               \n",
    "            else:\n",
    "                interactions = Variable(torch.FloatTensor(ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.LongTensor(batch))\n",
    "                cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "\n",
    "            # Predict and calculate loss\n",
    "            predictions = model(rows, cols)\n",
    "            self.currentLoss = self.loss_func(predictions, interactions)\n",
    "\n",
    "            # Backpropagate\n",
    "            self.currentLoss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            self.reg_loss_func.step()\n",
    "    \n",
    "    def train(self, numEpochs, batch_size, ratings,learningRate):\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.reg_loss_func = torch.optim.SGD(model.parameters(), lr=learningRate, weight_decay=1e-3)\n",
    "        for i in range(numEpochs):\n",
    "            print(i)\n",
    "            self.run_epoch(batch_size,ratings)\n",
    "            \n",
    "    \n",
    "    def convertLillMatrixToVariable(self,lillMatrix):\n",
    "        if self.useCUDA:\n",
    "            if lillMatrix.shape[0] == 1:\n",
    "                # we have a single matrix\n",
    "                return Variable(torch.cuda.LongTensor(lillMatrix.toarray()))\n",
    "            else:\n",
    "                return Variable(torch.cuda.LongTensor(lillMatrix.toarray()))\n",
    "        else:\n",
    "            if lillMatrix.shape[0] == 1:\n",
    "                # we have a single matrix\n",
    "                return Variable(torch.LongTensor(lillMatrix.toarray()))\n",
    "            else:\n",
    "                return Variable(torch.LongTensor(lillMatrix.toarray()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "CUDA not available, reverting to CPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Model\")\n",
    "model = MatrixFactorization(ratings.shape[0], ratings.shape[1], n_factors=2,useBias = False)\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 5\n",
    "BATCH_SIZE = 1000 #50\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-ce9f2f1a0bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-132-817ca9cbd135>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, numEpochs, batch_size, ratings, learningRate)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-132-817ca9cbd135>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, batch_size, ratings)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Backpropagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training Model\")\n",
    "model.train(EPOCH,BATCH_SIZE,ratings,LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loss: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Loss: {}\".format(model.getLoss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = model.convertLillMatrixToVariable(test_ratings[28665,:])\n",
    "cols = model.convertLillMatrixToVariable(test_ratings[:,0:1])\n",
    "# cols = Variable(torch.LongTensor(np.arange(test_ratings.shape[1])))\n",
    "# cols = Variable(torch.LongTensor(test_ratings[:,0].T.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65133])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42788, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 3D, 3D tensors at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518385717421/work/torch/lib/TH/generic/THTensorMath.c:1429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e5cb02035133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-801d412bc58d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, user, item)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#         print(self.user_factors(user))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#         print(self.item_factors(item))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;31m#         return (self.user_factors(user) * self.item_factors(item)).sum(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: matrices expected, got 3D, 3D tensors at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518385717421/work/torch/lib/TH/generic/THTensorMath.c:1429"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(rows,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42788, 2])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.LongTensor of size 1x65133]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.LongTensor(test_ratings[28665,:].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "  ⋮   \n",
       "    0\n",
       "    0\n",
       "    0\n",
       "[torch.LongTensor of size 42788x1]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.LongTensor(test_ratings[:,0].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictionVar = model.predict(Variable(torch.LongTensor(test_ratings[28665,:].toarray())), Variable(torch.LongTensor(test_ratings[:,0].toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-18441.40234375,  51097.3125    ],\n",
       "       [-18441.40234375,  51097.3125    ],\n",
       "       [-18441.40234375,  51097.3125    ],\n",
       "       ..., \n",
       "       [-18441.40234375,  51097.3125    ],\n",
       "       [-18441.40234375,  51097.3125    ],\n",
       "       [-18441.40234375,  51097.3125    ]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionVar.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42788.000000</td>\n",
       "      <td>42788.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-16091.040039</td>\n",
       "      <td>48935.441406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8824.510742</td>\n",
       "      <td>24505.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-49876.910156</td>\n",
       "      <td>-60190.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-18441.402344</td>\n",
       "      <td>51097.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-18441.402344</td>\n",
       "      <td>51097.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-18441.402344</td>\n",
       "      <td>51097.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14877.375977</td>\n",
       "      <td>106249.773438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1\n",
       "count  42788.000000   42788.000000\n",
       "mean  -16091.040039   48935.441406\n",
       "std     8824.510742   24505.070312\n",
       "min   -49876.910156  -60190.320312\n",
       "25%   -18441.402344   51097.312500\n",
       "50%   -18441.402344   51097.312500\n",
       "75%   -18441.402344   51097.312500\n",
       "max    14877.375977  106249.773438"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictionVar.data.cpu().numpy()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42788, 65133)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.convertLillMatrixToVariable(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,batch in enumerate(get_batch(BATCH_SIZE,test_ratings)):\n",
    "print(test_ratings)\n",
    "rows = Variable(torch.LongTensor(batch))\n",
    "cols = Variable(torch.LongTensor(np.arange(test_ratings.shape[1])))\n",
    "predictions = predict(rows, cols)\n",
    "print(predictions.data.cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.permutation(test_ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_ratings.shape[0]):\n",
    "    test_ratings[i:,].todense().max()\n",
    "    if (test_ratings[i:,].todense().max() > 0):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_ratings.shape[0]):\n",
    "    test_ratings[:,i].todense().max()\n",
    "    if (test_ratings[:,i].todense().max() > 0):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ratings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings[28665].toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings[:,0].T.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
