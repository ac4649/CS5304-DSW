{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "from scipy.sparse import lil_matrix\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Loaded Train\n",
      "Loaded Test\n"
     ]
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "print(\"Loading Data\")\n",
    "df_train = pd.read_csv('ml-10M100K/r3.train', sep='::', names=names,engine='python')\n",
    "print(\"Loaded Train\")\n",
    "df_test = pd.read_csv('ml-10M100K/r3.test', sep='::', names=names,engine='python')\n",
    "print(\"Loaded Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000044, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train.head()\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movielens_ratings(df):\n",
    "    n_users = max(df.user_id.unique())\n",
    "    n_items = max(df.item_id.unique())\n",
    "\n",
    "    interactions = lil_matrix( (n_users,n_items), dtype=float) #np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Training Data\n",
      "(71567, 65133)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Training Data\")\n",
    "ratings = get_movielens_ratings(df_train)\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Testing Data\n",
      "(42788, 65133)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Testing Data\")\n",
    "test_ratings = get_movielens_ratings(df_test)\n",
    "print(test_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_users, n_items, n_factors=5, useBias = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if torch.cuda.is_available(): # CHECK FOR CUDA AVAILABILITY\n",
    "            self.useCUDA = True\n",
    "            print(\"CUDA is being used\")\n",
    "        else:\n",
    "            print(\"CUDA not available, reverting to CPU\")\n",
    "            \n",
    "        if self.useCUDA: # IF IT IS AVAILABLE, USE IT\n",
    "            self.cuda() \n",
    "        \n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        # Also should consider fitting overall bias (self.mu term) and both user and item bias vectors\n",
    "        \n",
    "        ## Incorporation of Bias Term\n",
    "        if useBias:\n",
    "            self.user_bias = torch.nn.Embedding(n_users, 1, sparse = False)\n",
    "            self.item_bias = torch.nn.Embedding(n_itms, 1, sparse = False)\n",
    "        \n",
    "        \n",
    "        # Mu is 1x1, user_bias is 1xn_users. item_bias is 1xn_items\n",
    "        \n",
    "    def getLoss(self):\n",
    "        return self.currentLoss\n",
    "\n",
    "\n",
    "    currentLoss = 2\n",
    "    useCUDA = False\n",
    "#     loss_func = torch.nn.MSELoss()\n",
    "#     reg_loss_func = torch.optim.SGD(self.model.parameters(), lr=1e-6, weight_decay=1e-3)\n",
    "    \n",
    "    # For convenience when we want to predict a single user-item pair. \n",
    "    def predict(self, user, item):\n",
    "        # Need to fit bias factors\n",
    "#         prediction = self.user_bias(user) + self.item_bias(item)\n",
    "        #pred += (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "        return (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "#         return torch.dot(self.user_factors(user),self.item_factors(item))\n",
    "    \n",
    "    # Much more efficient batch operator. This should be used for training purposes\n",
    "    def forward(self, users, items):\n",
    "        # Need to fit bias factors\n",
    "        return torch.mm(self.user_factors(users),torch.transpose(self.item_factors(items),0,1))\n",
    "    \n",
    "    def get_batch(self,batch_size,ratings):\n",
    "        # Sort our data and scramble it\n",
    "        rows, cols = ratings.shape\n",
    "        p = np.random.permutation(rows)\n",
    "\n",
    "        # create batches\n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < rows:\n",
    "            batch = p[sindex:eindex]\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= rows:\n",
    "            batch = range(sindex,rows)\n",
    "            yield batch    \n",
    "    \n",
    "    def run_epoch(self,batch_size, ratings):\n",
    "        for i,batch in enumerate(self.get_batch(batch_size, ratings)):\n",
    "            # Set gradients to zero\n",
    "            self.reg_loss_func.zero_grad()\n",
    "\n",
    "            # Turn data into variables\n",
    "            if self.useCUDA:\n",
    "                interactions = Variable(torch.cuda.FloatTensor(ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.cuda.LongTensor(batch))\n",
    "                cols = Variable(torch.cuda.LongTensor(np.arange(ratings.shape[1])))               \n",
    "            else:\n",
    "                interactions = Variable(torch.FloatTensor(ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.LongTensor(batch))\n",
    "                cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "\n",
    "            # Predict and calculate loss\n",
    "            predictions = model(rows, cols)\n",
    "            self.currentLoss = self.loss_func(predictions, interactions)\n",
    "\n",
    "            # Backpropagate\n",
    "            self.currentLoss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            self.reg_loss_func.step()\n",
    "    \n",
    "    def train(self, numEpochs, batch_size, ratings,learningRate):\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.reg_loss_func = torch.optim.SGD(model.parameters(), lr=learningRate, weight_decay=1e-3)\n",
    "        for i in range(numEpochs):\n",
    "            print(i)\n",
    "            self.run_epoch(batch_size,ratings)\n",
    "            \n",
    "    \n",
    "    def convertLillMatrixToVariable(self,lillMatrix,transpose = False):\n",
    "        if self.useCUDA:\n",
    "            if lillMatrix.shape[0] == 1:\n",
    "                # we have a single matrix\n",
    "                return Variable(torch.cuda.LongTensor(lillMatrix.toarray()[0]))\n",
    "            else:\n",
    "                return Variable(torch.cuda.LongTensor(lillMatrix.toarray()))\n",
    "        else:\n",
    "            if lillMatrix.shape[0] == 1:\n",
    "                # we have a single matrix\n",
    "                return Variable(torch.LongTensor(lillMatrix.toarray()[0]))\n",
    "            else:\n",
    "                return Variable(torch.LongTensor(lillMatrix.toarray()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "CUDA not available, reverting to CPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Model\")\n",
    "model = MatrixFactorization(ratings.shape[0], ratings.shape[1], n_factors=2,useBias = False)\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 5\n",
    "BATCH_SIZE = 1000 #50\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Model\")\n",
    "model.train(EPOCH,BATCH_SIZE,ratings,LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Loss: {}\".format(model.getLoss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = model.convertLillMatrixToVariable(test_ratings[28665,:])\n",
    "cols = model.convertLillMatrixToVariable(test_ratings[:,0])\n",
    "# cols = Variable(torch.LongTensor(test_ratings[:,0].T.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [65133 x 2] and src [42788 x 1 x 2] to have the same number of elements, but got 130266 and 85576 elements respectively at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518385717421/work/torch/lib/TH/generic/THTensorMath.c:656",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-43052522d2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictionVar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-4850eebf3a0f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, user, item)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#pred += (self.user_factors(user) * self.item_factors(item)).sum(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#         return (self.user_factors(user) * self.item_factors(item)).sum(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Much more efficient batch operator. This should be used for training purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [65133 x 2] and src [42788 x 1 x 2] to have the same number of elements, but got 130266 and 85576 elements respectively at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518385717421/work/torch/lib/TH/generic/THTensorMath.c:656"
     ]
    }
   ],
   "source": [
    "predictionVar = model.predict(rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e+05 *\n",
       " 0.6861 -0.5846\n",
       " 0.6861 -0.5846\n",
       " 0.6861 -0.5846\n",
       "       ⋮        \n",
       " 0.6861 -0.5846\n",
       " 0.6861 -0.5846\n",
       " 0.6861 -0.5846\n",
       "[torch.FloatTensor of size 42788x2]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictionVar).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42788, 65133)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.convertLillMatrixToVariable(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,batch in enumerate(get_batch(BATCH_SIZE,test_ratings)):\n",
    "print(test_ratings)\n",
    "rows = Variable(torch.LongTensor(batch))\n",
    "cols = Variable(torch.LongTensor(np.arange(test_ratings.shape[1])))\n",
    "predictions = predict(rows, cols)\n",
    "print(predictions.data.cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.permutation(test_ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_ratings.shape[0]):\n",
    "    test_ratings[i:,].todense().max()\n",
    "    if (test_ratings[i:,].todense().max() > 0):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_ratings.shape[0]):\n",
    "    test_ratings[:,i].todense().max()\n",
    "    if (test_ratings[:,i].todense().max() > 0):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ratings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings[28665].toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings[:,0].T.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
