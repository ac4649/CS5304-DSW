{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import *\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = []\n",
    "for file in os.listdir(\"data/train_1\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        fileNames.append(file)\n",
    "# fileNamesDF = pd.DataFrame(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668bfba8483e443daf523015a8655ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=69), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#only take certain artist so that the probabilities aren't basically all false when doing the tupples\n",
    "minNumPaintingsPerArtist = 200\n",
    "\n",
    "# #for each artist, only take n of their paintings\n",
    "numPaintingsPerAuthor = 100\n",
    "\n",
    "\n",
    "trainInfo = pd.read_csv('data/train_info.csv')\n",
    "mostPopularArtists = trainInfo['artist'].value_counts()[trainInfo['artist'].value_counts() > minNumPaintingsPerArtist]\n",
    "\n",
    "trainInfo = trainInfo[trainInfo['filename'].isin(fileNames)]\n",
    "fileNamesDFAll = trainInfo[trainInfo['artist'].isin(mostPopularArtists.index)]\n",
    "\n",
    "\n",
    "fileNamesDF = pd.DataFrame()\n",
    "for artist in tqdm(mostPopularArtists.index):\n",
    "    fileNamesDF = fileNamesDF.append(trainInfo[trainInfo['artist'] == artist][:numPaintingsPerAuthor])\n",
    "    \n",
    "fileNamesDF = fileNamesDF['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the all_data_info for the dataset we are using\n",
    "allInfo = pd.read_csv('data/all_data_info.csv')\n",
    "allInfo = allInfo[allInfo['new_filename'].isin(fileNamesDF)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDF = pd.DataFrame(allInfo['new_filename'])\n",
    "featuresDF['pixelsx'] = allInfo['pixelsx']\n",
    "featuresDF['pixelsy'] = allInfo['pixelsy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSeries(series, maxNum):\n",
    "    series = series/maxNum\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurizeImage(filename):\n",
    "    # Extract the features from the actual image\n",
    "    jpgfile = Image.open(\"data/train_1/\" + filename)\n",
    "#     print(jpgfile)\n",
    "    \n",
    "    bands = jpgfile.getbands()\n",
    "    if bands[0] == 'L':\n",
    "        # grayscale image\n",
    "        imageDF = pd.DataFrame(list(jpgfile.getdata()),columns=['grayscale'])\n",
    "#         imageDF['grayscale'] = normalizeSeries(imageDF['grayscale',])\n",
    "    elif len(bands) == 4:\n",
    "        #get red, green and blue chanels \n",
    "        imageDF = pd.DataFrame(list(jpgfile.getdata()),columns=['red','green','blue','alpha'])\n",
    "        imageDF['red'] = normalizeSeries(imageDF['red'],255)\n",
    "        imageDF['green'] = normalizeSeries(imageDF['green'],255)\n",
    "        imageDF['blue'] = normalizeSeries(imageDF['blue'],255)  \n",
    "        imageDF['alpha'] = normalizeSeries(imageDF['alpha'],255)  \n",
    "    elif len(bands) == 3:\n",
    "        #get red, green and blue chanels \n",
    "        imageDF = pd.DataFrame(list(jpgfile.getdata()),columns=['red','green','blue'])\n",
    "        imageDF['red'] = normalizeSeries(imageDF['red'],255)\n",
    "        imageDF['green'] = normalizeSeries(imageDF['green'],255)\n",
    "        imageDF['blue'] = normalizeSeries(imageDF['blue'],255)  \n",
    "    else:\n",
    "        imageDF = pd.DataFrame(list(jpgfile.getdata()))\n",
    "        print(bands)\n",
    "        return imageDF, bands\n",
    "\n",
    "    return imageDF.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   511,    697,    773,    867,    921,    933,    995,   1277,\n",
       "              1332,   1546,\n",
       "            ...\n",
       "            101294, 101629, 101725, 102085, 102113, 102402, 102565, 102862,\n",
       "            103030, 103049],\n",
       "           dtype='int64', length=1661)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([   511,    697,    773,    867,    921,    933,    995,   1277,\n",
      "              1332,   1546,\n",
      "            ...\n",
      "            101294, 101629, 101725, 102085, 102113, 102402, 102565, 102862,\n",
      "            103030, 103049],\n",
      "           dtype='int64', length=1661)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8ad19b99be40bbb603c9b689194b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1661), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "imageFeaturesDF = pd.DataFrame(index=featuresDF.index,columns=['features']) \n",
    "print(imageFeaturesDF.index)\n",
    "for row in tqdm(list(featuresDF.index)):\n",
    "    imageFeatures = featurizeImage(featuresDF.loc[row]['new_filename'])\n",
    "    imageFeaturesDF.loc[row]['features'] = imageFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>[0.5428758332157436, 0.567912843558902, 0.4950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>[0.5401178080546106, 0.5401178080546106, 0.540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>[109.78050646073648]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>[0.498340133186191, 0.498340133186191, 0.49834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>[0.6727659245903405, 0.6727659245903405, 0.672...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              features\n",
       "511  [0.5428758332157436, 0.567912843558902, 0.4950...\n",
       "697  [0.5401178080546106, 0.5401178080546106, 0.540...\n",
       "773                               [109.78050646073648]\n",
       "867  [0.498340133186191, 0.498340133186191, 0.49834...\n",
       "921  [0.6727659245903405, 0.6727659245903405, 0.672..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageFeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFeaturesDF.to_csv('image_features_extracted2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDF['imgFeatures'] = imageFeaturesDF['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_filename</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>imgFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>13211.jpg</td>\n",
       "      <td>4340.0</td>\n",
       "      <td>2952.0</td>\n",
       "      <td>[0.5428758332157436, 0.567912843558902, 0.4950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>14108.jpg</td>\n",
       "      <td>3899.0</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>[0.5401178080546106, 0.5401178080546106, 0.540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>1155.jpg</td>\n",
       "      <td>3899.0</td>\n",
       "      <td>2732.0</td>\n",
       "      <td>[109.78050646073648]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>13673.jpg</td>\n",
       "      <td>3887.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>[0.498340133186191, 0.498340133186191, 0.49834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>16144.jpg</td>\n",
       "      <td>3905.0</td>\n",
       "      <td>2538.0</td>\n",
       "      <td>[0.6727659245903405, 0.6727659245903405, 0.672...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    new_filename  pixelsx  pixelsy  \\\n",
       "511    13211.jpg   4340.0   2952.0   \n",
       "697    14108.jpg   3899.0   2874.0   \n",
       "773     1155.jpg   3899.0   2732.0   \n",
       "867    13673.jpg   3887.0   2601.0   \n",
       "921    16144.jpg   3905.0   2538.0   \n",
       "\n",
       "                                           imgFeatures  \n",
       "511  [0.5428758332157436, 0.567912843558902, 0.4950...  \n",
       "697  [0.5401178080546106, 0.5401178080546106, 0.540...  \n",
       "773                               [109.78050646073648]  \n",
       "867  [0.498340133186191, 0.498340133186191, 0.49834...  \n",
       "921  [0.6727659245903405, 0.6727659245903405, 0.672...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareImages(img1, img2):\n",
    "    \n",
    "    diffx = np.abs(img1['pixelsx']-img2['pixelsx']) / (img1['pixelsx'] + img2['pixelsx'])\n",
    "    diffy = np.abs(img1['pixelsy']-img2['pixelsy']) / (img1['pixelsy'] + img2['pixelsy'])\n",
    "    \n",
    "    diffSize = (diffx + diffy)/2\n",
    "    \n",
    "    img1Features = img1['imgFeatures']\n",
    "    img2Features = img2['imgFeatures']\n",
    "    \n",
    "    imgFeatureScore = 0\n",
    "    \n",
    "    if (len(img1Features) == len(img2Features)):\n",
    "        imgFeatureDiffs = np.abs(img1Features - img2Features)\n",
    "        imgFeatureScore = sum(imgFeatureDiffs)\n",
    "\n",
    "    score = (diffSize+imgFeatureScore)/2\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePrediction(score,threshold):\n",
    "    if score > threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def generatePredictions(scores,threshold):\n",
    "    predictions = []\n",
    "    for curScore in tqdm(scores,leave=False):\n",
    "        predictions.append(generatePrediction(curScore,threshold))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainThreshold(featuresTrain,maxNumIterations = 100,initialProb = 0.5, increaseRate = 0.001):\n",
    "    \n",
    "    probThreshold = initialProb\n",
    "    prevAccuracy = 0\n",
    "\n",
    "    for i in tqdm(range(maxNumIterations),leave=False):\n",
    "        # the score represents how similar two images are\n",
    "\n",
    "        scores = []\n",
    "        iloc1 = featuresTrain.sample(frac=0.5).index\n",
    "        iloc2 = featuresTrain.sample(frac=0.5).index\n",
    "        # print(len(iloc2))\n",
    "        # print(nTrials)\n",
    "\n",
    "        for i, loc in tqdm(enumerate(iloc1),leave=False):\n",
    "            scores.append(compareImages(featuresTrain.loc[loc],featuresTrain.loc[iloc2[i]]))\n",
    "\n",
    "        filenames1 = featuresTrain.loc[iloc1]['new_filename'].values\n",
    "        filenames2 = featuresTrain.loc[iloc2]['new_filename'].values\n",
    "\n",
    "\n",
    "        truth = trainInfo[trainInfo['filename'].isin(filenames1)]['artist'].values == trainInfo[trainInfo['filename'].isin(filenames2)]['artist'].values\n",
    "        predictions = generatePredictions(scores,probThreshold)\n",
    "\n",
    "        accuracy = (predictions == truth).sum()/len(predictions == truth)\n",
    "        if (accuracy < prevAccuracy):\n",
    "            return probThreshold, prevAccuracy\n",
    "        \n",
    "        probThreshold += increaseRate\n",
    "    \n",
    "    return probThreshold, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDevAcc(featuresTrain,probability):\n",
    "\n",
    "    # the score represents how similar two images are\n",
    "    scores = []\n",
    "    iloc1 = featuresTrain.sample(frac=0.5).index\n",
    "    iloc2 = featuresTrain.sample(frac=0.5).index\n",
    "\n",
    "    # print(len(iloc2))\n",
    "    # print(nTrials)\n",
    "\n",
    "    for i, loc in tqdm(enumerate(iloc1),leave=False):\n",
    "        scores.append(compareImages(featuresTrain.loc[loc],featuresTrain.loc[iloc2[i]]))\n",
    "\n",
    "    filenames1 = featuresTrain.loc[iloc1]['new_filename'].values\n",
    "    filenames2 = featuresTrain.loc[iloc2]['new_filename'].values\n",
    "\n",
    "\n",
    "    truth = trainInfo[trainInfo['filename'].isin(filenames1)]['artist'].values == trainInfo[trainInfo['filename'].isin(filenames2)]['artist'].values\n",
    "    predictions = generatePredictions(scores,probThreshold)\n",
    "\n",
    "    accuracy = (predictions == truth).sum()/len(predictions == truth)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105eaeefc37546f498a23348f09c9638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed90abe38d634dedb08ef533007966bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=498), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrien/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-477-f99a7c5dae1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfeaturesDev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeaturesDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     featuresTest = featuresDF.drop(featuresDev.index).drop(featuresTrain.index).sample(n=nTest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlearnedThreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mthresholds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearnedThreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainAccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmeanDevAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-472-25eb59bbb537>\u001b[0m in \u001b[0;36mtrainThreshold\u001b[0;34m(featuresTrain, maxNumIterations, initialProb, increaseRate)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratePredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobThreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mprevAccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprobThreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevAccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "nTrainFraction = 0.6\n",
    "nDevFraction = 0.4\n",
    "\n",
    "thresholds = []\n",
    "devAccuracies = []\n",
    "numberSamples = 10\n",
    "for i in tqdm(range(numberSamples)):\n",
    "    featuresTrain = featuresDF.sample(frac=nTrainFraction)\n",
    "    featuresDev = featuresDF.drop(featuresTrain.index)\n",
    "#     featuresTest = featuresDF.drop(featuresDev.index).drop(featuresTrain.index).sample(n=nTest)\n",
    "    learnedThreshold, trainAccuracy = trainThreshold(featuresTrain,100,0.5,0.001)\n",
    "    thresholds.append((learnedThreshold,trainAccuracy))\n",
    "    meanDevAccuracy = 0\n",
    "    accuraciesDev = []\n",
    "    for i in range(10):\n",
    "        accuraciesDev.append(computeDevAcc(featuresDev,learnedThreshold))\n",
    "    meanDevAccuracy = np.mean(accuraciesDev)\n",
    "    devAccuracies.append(meanDevAccuracy)\n",
    "    \n",
    "print(thresholds)\n",
    "print(devAccuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
