{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "from scipy.sparse import lil_matrix\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Loaded Train\n",
      "Loaded Test\n"
     ]
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "print(\"Loading Data\")\n",
    "df_train = pd.read_csv('ml-10M100K/r3.train', sep='::', names=names,engine='python')\n",
    "print(\"Loaded Train\")\n",
    "df_test = pd.read_csv('ml-10M100K/r3.test', sep='::', names=names,engine='python')\n",
    "print(\"Loaded Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1      122     5.0  838985046\n",
       "1        1      185     5.0  838983525\n",
       "2        1      231     5.0  838983392\n",
       "3        1      292     5.0  838983421\n",
       "4        1      316     5.0  838983392"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000044, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train.head()\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movielens_ratings(df):\n",
    "    n_users = max(df.user_id.unique())\n",
    "    n_items = max(df.item_id.unique())\n",
    "\n",
    "    interactions = lil_matrix( (n_users,n_items), dtype=float) #np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Training Data\n",
      "(71567, 65133)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Training Data\")\n",
    "ratings = get_movielens_ratings(df_train)\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Testing Data\n",
      "(42788, 65133)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Testing Data\")\n",
    "test_ratings = get_movielens_ratings(df_test)\n",
    "print(test_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_users, n_items, n_factors=5, useBias = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if torch.cuda.is_available(): # CHECK FOR CUDA AVAILABILITY\n",
    "            self.useCUDA = True\n",
    "            print(\"CUDA is being used\")\n",
    "        else:\n",
    "            print(\"CUDA not available, reverting to CPU\")\n",
    "            \n",
    "        if self.useCUDA: # IF IT IS AVAILABLE, USE IT\n",
    "            self.cuda() \n",
    "        \n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        # Also should consider fitting overall bias (self.mu term) and both user and item bias vectors\n",
    "        \n",
    "        ## Incorporation of Bias Term\n",
    "        if useBias:\n",
    "            self.user_bias = torch.nn.Embedding(n_users, 1, sparse = False)\n",
    "            self.item_bias = torch.nn.Embedding(n_itms, 1, sparse = False)\n",
    "        \n",
    "        \n",
    "        # Mu is 1x1, user_bias is 1xn_users. item_bias is 1xn_items\n",
    "        \n",
    "    def getLoss(self):\n",
    "        return self.currentLoss\n",
    "\n",
    "\n",
    "    currentLoss = 2\n",
    "    useCUDA = False\n",
    "    \n",
    "    interactions = False\n",
    "#     loss_func = torch.nn.MSELoss()\n",
    "#     reg_loss_func = torch.optim.SGD(self.model.parameters(), lr=1e-6, weight_decay=1e-3)\n",
    "    \n",
    "    # For convenience when we want to predict a single user-item pair. \n",
    "    def predict(self, user, item):\n",
    "        # Need to fit bias factorsx\n",
    "        print(\"Predicting\")\n",
    "        \n",
    "        print(self.user_factors(user))\n",
    "        print(torch.transpose(self.item_factors(item),0,1))\n",
    "\n",
    "#         return torch.mm(self.user_factors(user)[0],torch.transpose(self.item_factors(item),0,1)[0])\n",
    "        return (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "    \n",
    "    \n",
    "#         return torch.dot(self.user_factors(user),self.item_factors(item))\n",
    "    \n",
    "    # Much more efficient batch operator. This should be used for training purposes\n",
    "    def forward(self, users, items):\n",
    "        # Need to fit bias factors\n",
    "#         print(\"Forward\")\n",
    "        return torch.mm(self.user_factors(users),torch.transpose(self.item_factors(items),0,1))\n",
    "    \n",
    "    def get_batch(self,batch_size,ratings):\n",
    "        # Sort our data and scramble it\n",
    "        rows, cols = ratings.shape\n",
    "        p = np.random.permutation(rows)\n",
    "\n",
    "        # create batches\n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < rows:\n",
    "            batch = p[sindex:eindex]\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= rows:\n",
    "            batch = range(sindex,rows)\n",
    "            yield batch \n",
    "    \n",
    "    def run_test(self,batch_size,ratings_test):\n",
    "        predictionsArray = []\n",
    "        losses = []\n",
    "        for i,batch in enumerate(model.get_batch(batch_size,ratings_test)):\n",
    "            \n",
    "            if self.useCUDA:\n",
    "                interactions = Variable(torch.cuda.FloatTensor(ratings_test[batch, :].toarray()))\n",
    "                rows = Variable(torch.cuda.LongTensor(batch))\n",
    "                cols = Variable(torch.cuda.LongTensor(np.arange(ratings_test.shape[1])))               \n",
    "            else:\n",
    "                interactions = Variable(torch.FloatTensor(ratings_test[batch, :].toarray()))\n",
    "                rows = Variable(torch.LongTensor(batch))\n",
    "                cols = Variable(torch.LongTensor(np.arange(ratings_test.shape[1])))\n",
    "\n",
    "            # Predict and calculate loss\n",
    "            predictions = model(rows, cols)\n",
    "#             print(type(predictions))\n",
    "            predictionsArray.append(predictions.data.cpu().numpy())\n",
    "            losses.append(self.loss_func(predictions, interactions))\n",
    "        return predictionsArray, losses\n",
    "    \n",
    "    def run_epoch(self,batch_size, ratings):\n",
    "        for i,batch in enumerate(self.get_batch(batch_size, ratings)):\n",
    "            # Set gradients to zero\n",
    "            self.reg_loss_func.zero_grad()\n",
    "\n",
    "#             print(type(batch))\n",
    "            # Turn data into variables\n",
    "            if self.useCUDA:\n",
    "#                 print(\"using cuda\")\n",
    "                interactions = Variable(torch.cuda.FloatTensor(ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.cuda.LongTensor(batch))\n",
    "                cols = Variable(torch.cuda.LongTensor(np.arange(ratings.shape[1])))               \n",
    "            else:\n",
    "                interactions = Variable(torch.FloatTensor(ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.LongTensor(batch))\n",
    "                cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "\n",
    "#             print(type(rows))\n",
    "#             print(type(cols))\n",
    "            # Predict and calculate loss\n",
    "            predictions = model(rows, cols)\n",
    "#             print(predictions)\n",
    "            self.currentLoss = self.loss_func(predictions, interactions)\n",
    "\n",
    "            # Backpropagate\n",
    "            self.currentLoss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            self.reg_loss_func.step()\n",
    "    \n",
    "    def train(self, numEpochs, batch_size, ratings,learningRate):\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.reg_loss_func = torch.optim.SGD(model.parameters(), lr=learningRate, weight_decay=1e-3)\n",
    "        for i in range(numEpochs):\n",
    "            print(\"Epoch {}\".format(i))\n",
    "            self.run_epoch(batch_size,ratings)\n",
    "            \n",
    "    def convertArryToVariable(self, array):\n",
    "        if self.useCUDA:\n",
    "            return Variable(torch.cuda.LongTensor(array))\n",
    "        else:\n",
    "            return Variable(torch.LongTensor(array))\n",
    "\n",
    "\n",
    "    \n",
    "    def convertLillMatrixToVariable(self,lillMatrix):\n",
    "        if self.useCUDA:\n",
    "            if lillMatrix.shape[0] == 1:\n",
    "                # we have a single matrix\n",
    "                return Variable(torch.cuda.LongTensor(lillMatrix.toarray()))\n",
    "            else:\n",
    "                return Variable(torch.cuda.LongTensor(lillMatrix.toarray()))\n",
    "        else:\n",
    "            if lillMatrix.shape[0] == 1:\n",
    "                # we have a single matrix\n",
    "                return Variable(torch.LongTensor(lillMatrix.toarray()))\n",
    "            else:\n",
    "                return Variable(torch.LongTensor(lillMatrix.toarray()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "CUDA is being used\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Model\")\n",
    "model = MatrixFactorization(ratings.shape[0], ratings.shape[1], n_factors=2,useBias = False)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 1\n",
    "BATCH_SIZE = 1000 #50\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Model\")\n",
    "model.train(EPOCH,BATCH_SIZE,ratings,LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loss: Variable containing:\n",
      " 1.9848\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Loss: {}\".format(model.getLoss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at c:\\anaconda2\\conda-bld\\pytorch_1519496000060\\work\\torch\\lib\\thc\\generic/THCStorage.c:82",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-52ee0a211649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_ratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-7df119cea52d>\u001b[0m in \u001b[0;36mrun_test\u001b[1;34m(self, batch_size, ratings_test)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0museCUDA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0minteractions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at c:\\anaconda2\\conda-bld\\pytorch_1519496000060\\work\\torch\\lib\\thc\\generic/THCStorage.c:82"
     ]
    }
   ],
   "source": [
    "model.run_test(10,test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.convertLillMatrixToVariable(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.convertArryToVariable(np.arange(test_ratings.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(rows,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(prediction.sum(1)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Variable(torch.LongTensor(test_ratings[28665,:].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Variable(torch.LongTensor(test_ratings[:,0].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictionVar = model.predict(Variable(torch.LongTensor(test_ratings[28665,:].toarray())), Variable(torch.LongTensor(test_ratings[:,0].toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionVar.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predictionVar.data.cpu().numpy()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.convertLillMatrixToVariable(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i,batch in enumerate(get_batch(BATCH_SIZE,test_ratings)):\n",
    "print(test_ratings)\n",
    "rows = Variable(torch.LongTensor(batch))\n",
    "cols = Variable(torch.LongTensor(np.arange(test_ratings.shape[1])))\n",
    "predictions = predict(rows, cols)\n",
    "print(predictions.data.cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.permutation(test_ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(test_ratings.shape[0]):\n",
    "    test_ratings[i:,].todense().max()\n",
    "    if (test_ratings[i:,].todense().max() > 0):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(test_ratings.shape[0]):\n",
    "    test_ratings[:,i].todense().max()\n",
    "    if (test_ratings[:,i].todense().max() > 0):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ratings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratings[28665].toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratings[:,0].T.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
