{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an index file for the huge data file\n",
    "def createIndex(filePath):\n",
    "    file = open(filePath,'r');\n",
    "    indexFilePath = filePath+\"_index.csv\"\n",
    "    indexFile = open(indexFilePath,'w');\n",
    "    indexFile.close()\n",
    "    \n",
    "    offset = 0\n",
    "    lineNumber = 0\n",
    "    for line in file:\n",
    "#         clear_output(wait=True)\n",
    "#         print(lineNumber)\n",
    "        indexFile = open(indexFilePath,'a');\n",
    "        indexFile.write(str(lineNumber) + \",\" + str(offset) + \"\\n\")\n",
    "        indexFile.close()\n",
    "        lineNumber = lineNumber + 1\n",
    "        offset += len(line)\n",
    "    file.close()\n",
    "    return indexFilePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateNIndecesFrom(n, rangeOfIndeces):\n",
    "    print(\"Generating \" + str(n) + \" indeces from range\")\n",
    "    allIndeces = random.sample(rangeOfIndeces, n)\n",
    "    allIndeces = pd.Series(data = allIndeces)\n",
    "    allIndeces = allIndeces.sort_values().reset_index().drop(['index'],axis=1)\n",
    "    allIndeces.columns = ['Index'];\n",
    "    return allIndeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the 2000000 data points\n"
     ]
    }
   ],
   "source": [
    "#Load or Generate the 2M indeces to use\n",
    "twoMIndeces = pd.read_csv('2MIndeces.csv',squeeze = True)\n",
    "if (twoMIndeces.shape[0] != 2000000):\n",
    "    print(\"There were not 2000000 data points\")\n",
    "    twoMIndeces = generateNIndecesFrom(2000000,range(0,47999999))\n",
    "    twoMIndeces.to_csv('2MIndeces.csv')\n",
    "else:\n",
    "    print(\"Loaded the 2000000 data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateSubSet(file,dataFrame,indexValues,numRowsPerItteration,totalNumRows,column_headers):\n",
    "    totalNumIterations = int(totalNumRows/numRowsPerItteration)\n",
    "    prevsize = 0\n",
    "    for i in range(totalNumIterations):\n",
    "        curData = pd.read_table(file,skiprows = i * numRowsPerItteration,nrows = numRowsPerItteration,header=None)\n",
    "        curData.index = [i for i in range(i*numRowsPerItteration,i*numRowsPerItteration + numRowsPerItteration)]\n",
    "        curData.columns = column_headers\n",
    "        curData['Index'] = curData.index\n",
    "\n",
    "        curIndexRange = indexValues['Index'][(indexValues['Index'] < (i*numRowsPerItteration + numRowsPerItteration)) & (indexValues['Index'] > (i*numRowsPerItteration))]\n",
    "        curData = curData[curData['Index'].isin(curIndexRange)]\n",
    "\n",
    "        \n",
    "        dataFrame = pd.concat([dataFrame,curData])\n",
    "\n",
    "        if (dataFrame.shape[0] - prevsize) > 10000:\n",
    "            clear_output(wait=True)\n",
    "            print(dataFrame.shape[0])\n",
    "            prevsize = dataFrame.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200369\n"
     ]
    }
   ],
   "source": [
    "column_headers = pd.read_csv('data_columns.csv',squeeze = True)\n",
    "allData = pd.DataFrame()\n",
    "generateSubSet('dac/train.txt',allData,twoMIndeces,100000,48000000,column_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537038, 41)\n"
     ]
    }
   ],
   "source": [
    "# column_headers = pd.read_csv('data_columns.csv',squeeze = True)\n",
    "# allData = pd.DataFrame()\n",
    "\n",
    "# numRowsPerItteration = 100000\n",
    "# # numiterations = 0\n",
    "# totalNumRows = 48000000\n",
    "# totalNumIterations = int(totalNumRows/numRowsPerItteration)\n",
    "# for i in range(totalNumIterations):\n",
    "#     curData = pd.read_table('dac/train.txt',skiprows = i * numRowsPerItteration,nrows = numRowsPerItteration,header=None)\n",
    "#     curData.index = [i for i in range(i*numRowsPerItteration,i*numRowsPerItteration + numRowsPerItteration)]\n",
    "#     curData.columns = column_headers\n",
    "#     curData['Index'] = curData.index\n",
    "    \n",
    "#     curIndexRange = twoMIndeces['Index'][(twoMIndeces['Index'] < (i*numRowsPerItteration + numRowsPerItteration)) & (twoMIndeces['Index'] > (i*numRowsPerItteration))]\n",
    "#     curData = curData[curData['Index'].isin(curIndexRange)]\n",
    "# #     print(allData.shape)\n",
    "# #     print(curData.head())\n",
    "#     allData = pd.concat([allData,curData])\n",
    "#     clear_output(wait=True)\n",
    "#     print(allData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allData.to_csv('2MDataFinalDesktop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
